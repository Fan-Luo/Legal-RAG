---
title: Legal-RAG
emoji: "ü§ñ"
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
pinned: true
author: Fan Luo 
---

[![HuggingFace Spaces](https://img.shields.io/badge/Space-Legal--RAG-blue?logo=huggingface)](https://huggingface.co/spaces/flora-l/Legal-RAG)
[![Kaggle Notebook](https://img.shields.io/badge/Kaggle-Notebook-blue)](https://www.kaggle.com/code/fanlcs/retrieval-performance-evaluation)
[![Colab Notebook](https://img.shields.io/badge/Run-Colab-blue?logo=googlecolab)](https://colab.research.google.com/drive/1TRp4d_VwlcSY8f78psuCNX_90WA3g6qS?usp=sharing)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://www.apache.org/licenses/LICENSE-2.0)
 

## What is Legal-RAG?
[Legal-RAG](https://fan-luo.github.io/Legal-RAG/) is an open-source, end-to-end legal Retrieval-Augmented Generation (RAG) system centered on statutory text. It integrates QueryType-aware routing, hybrid retrieval, bounded graph-augmented context expansion, and provider-agnostic generation. Running OpenAI models with an OPENAI_API_KEY as the generation model is optional; you can deploy with GPU to enable local models (default: Qwen), and other open-source models are configurable.

<video src="docs/project.mp4" width="720" height="480" controls muted style="display: block; margin: 0 auto 50px auto;"></video>


## Online Demo  

- Option 1 ‚Äî Hosted Demo: [Hugging Face Spaces](https://huggingface.co/spaces/flora-l/Legal-RAG) (no GPU, slower, requires OpenAI key)
- Option 2 ‚Äî Self‚ÄëLaunch Demo: [Colab notebook](https://colab.research.google.com/drive/1bDlIFzHvnlR-U3lWVGLJAGq3KwcpvlxG?usp=sharing) (launch the server on GPU, no OpenAI key required)


<a class="github-video">https://github.com/user-attachments/assets/1a380d62-d909-480a-8618-a03f3015e1bd</a>


## Features

### Law-aware RAG
- Explicit article-level chunking
- Law-specific metadata (chapter / section / article number)
- Retrieval results are inspectable and auditable
- Language-aware corpus routing (zh/en)

### Hybrid Retrieval
- Dense retrieval: FAISS
- Sparse retrieval: BM25
- ColBERT (late interaction)
- Weighted fusion

### Query Routing & Graph Awareness
- Lightweight law_graph for structural reasoning
- Router decides between:
  - pure retrieval
  - graph-assisted RAG
- Clear extension point for richer legal knowledge graphs

### Online PDF Ingestion (Incremental Indexing)
- Upload PDFs ‚Üí parse ‚Üí chunk ‚Üí JSONL
- Incremental FAISS add
- BM25 rebuild in background
 

## System Architecture
The system is organized into four clearly separated layers:

1. Offline Build
  Law text preprocessing, index construction, graph building

2. Index Artifacts
  FAISS, BM25, and law_graph as immutable read models

3. Online Ingestion
  PDF upload ‚Üí background incremental indexing

4. Online Serving (RAG + Routing)
  FastAPI + RagPipeline + Router + LLM

See the architecture diagram for the full data flow.

<img src="docs/architecture.png" alt="Legal-RAG Architecture" width="800"/>

 
## Quickstart (Local)
### 1. Clone & install
```bash
git clone https://github.com/Fan-Luo/Legal-RAG.git
cd Legal-RAG
pip install -r requirements.txt
````

### 2. Prepare law data & build index

The default corpus includes:

- Chinese: PRC Civil Code
- English: Uniform Commercial Code (UCC)

Queries are routed to language-specific corpora and indexes.

```bash
# preprocess law text into structured JSONL
python -m scripts.preprocess_law

# build FAISS + BM25 indexes
python -m scripts.build_index

# build law_graph
python -m scripts.build_graph
````
Artifacts are generated per language:

- `data/processed/law_zh.jsonl`, `data/processed/law_en.jsonl`
- `data/index/zh/...`, `data/index/en/...`
- `data/graph/law_graph_zh.jsonl`, `data/graph/law_graph_en.jsonl`

### 3. Start API service
```bash
python -m uvicorn legalrag.api.server:app --host 127.0.0.1 --port 8000 
````

### 4. Launch Demo
visit http://127.0.0.1:8000/ or http://127.0.0.1:8000/ui/
 

## Example

```python
from legalrag.config import AppConfig
from legalrag.pipeline.rag_pipeline import RagPipeline

cfg = AppConfig.load()
pipeline = RagPipeline(cfg)

question = "What standards must goods satisfy to be merchantableÔºü"
ans = pipeline.answer(question)

print(ans.answer)
``` 

## LLM Backends & Cost Model
Supported backends:

- Local LLM (Qwen series, need GPU and enough memory)
- OpenAI-compatible API (need to provide OpenAI API key)
  - No API key is collected via UI
  - LLM keys are read only from environment variables
Note: If no key is provided and no local model loaded, the system gracefully degrades


## Project Structure

```
Legal-RAG/
‚îÇ
‚îú‚îÄ‚îÄ legalrag/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py                   
‚îÇ   ‚îú‚îÄ‚îÄ schemas.py                 # LawChunk / RetrievalHit / RoutingDecision / RagAnswer
‚îÇ   ‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ gateway.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ client.py              # Qwen / OpenAI LLMClient 
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ routing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ legal_issue_extractor.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.py              # QueryType + Graph/RAG Suggestions
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ retrieval/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ builders
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dense_retriever.py     # Dense (BGE + FAISS)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ vector_store.py        
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bm25_retriever.py      # Sparse (BM25 + jieba)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ colbert_retriever.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hybrid_retriever.py    # Dense + Sparse + Colbert + Graph + Rerank
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ by_lang_retriever.py   # zh/en routing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ corpus_loader.py       # read all chunks from processed_dir
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ incremental_indexer.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_retriever.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ graph_store.py         # law_graph / legal_kg  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rerankers.py
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pdf/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parser.py              # pdfplumber + OCR fallback
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ ingest/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_queue.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ingestor.py            # PDFIngestor 
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ pipeline/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ rag_pipeline.py        # Graph-aware RAG Core Inference
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ prompts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prompt_zh.json         # Chinese prompt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompt_en.json         # English prompt
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lang.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logger.py             
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text.py                
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ api/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îî‚îÄ‚îÄ server.py              # FastAPIÔºà/rag/retrieve, /rag/answer, /ingest/pdfÔºâ
‚îÇ
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ index.html
‚îÇ   ‚îî‚îÄ‚îÄ demo.qmd
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_law.py          # parse law ‚Üí LawChunk JSONL
‚îÇ   ‚îú‚îÄ‚îÄ build_index.py             # FAISS + BM25 + Colbert indexes
‚îÇ   ‚îú‚îÄ‚îÄ build_graph.py             # law_graph / legal_kg  
‚îÇ   ‚îú‚îÄ‚îÄ bgenerate_synthetic_data.py
‚îÇ   ‚îî‚îÄ‚îÄ evaluate_retrieval.py      # Hit@K / MRR / nDCG
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_Launch_the_UI.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_LegalRAG_Pipeline.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_Retrieval_Performance_Evaluation.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_Law_Graph_Visualization.ipynb
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                         
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ minfadian.txt            
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ucc/                    
‚îÇ   ‚îú‚îÄ‚îÄ processed/                 # law_zh.jsonl / law_en.jsonl
‚îÇ   ‚îú‚îÄ‚îÄ index/                     # faiss/bm25/colbert per language
‚îÇ   ‚îî‚îÄ‚îÄ graph/                     # law_graph_zh.jsonl / law_graph_en.jsonl
‚îÇ   ‚îî‚îÄ‚îÄ eval/
‚îÇ       
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.mmd
‚îÇ   ‚îî‚îÄ‚îÄ architecture.png
‚îÇ 
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_router.py
‚îÇ   ‚îî‚îÄ‚îÄ test_retrieval.py
‚îÇ 
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ README-zh.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ _quarto.yml
‚îú‚îÄ‚îÄ index.qmd
‚îú‚îÄ‚îÄ app.py                           # Hugging Face Space entry
‚îú‚îÄ‚îÄ Dockerfile
‚îî‚îÄ‚îÄ .gitignore                       

```


## Who is this project for?
This repository is intended for:

- Engineers exploring RAG system design
- Researchers working on legal NLP / AI + law
- Practitioners interested in traceable AI systems
- Candidates demonstrating architecture-level thinking

> ‚ö†Ô∏è This project provides legal information assistance for educational and research purposes only and does not constitute legal advice. Users should not rely on this project as a substitute for professional legal counsel. The authors and contributors disclaim any liability for any direct or indirect consequences arising from the use of this project.

 

## Extensibility

Legal-RAG is intentionally structured to support:

- richer legal knowledge graphs
- multi-document reasoning
- multi-tenant isolation
- BYOK (Bring Your Own Key) SaaS models

These are architectural affordances, not product promises.



## License
Apache License 2.0

This repository contains source code only.
Users are responsible for complying with the licenses of any models or APIs they choose to integrate.
