[
  {
    "objectID": "README-zh.html",
    "href": "README-zh.html",
    "title": "",
    "section": "",
    "text": "Code\næ³•å¾‹æ¡æ–‡æ£€ç´¢ã€é—®ç­”ä¸æ¨ç†ç³»ç»Ÿ\nLegal-RAG ä»¥æ³•å¾‹æ–‡æœ¬ä¸ºæ ¸å¿ƒè¯­æ–™ï¼Œå®Œæˆæ¡æ–‡é¢„å¤„ç†ã€BM25/FAISS/ColBERT ç´¢å¼•ä¸ Graph çš„æ„å»ºï¼Œå¹¶é€šè¿‡ FastAPI æä¾›æ£€ç´¢ä¸é—®ç­”æœåŠ¡ï¼Œå¯ç»“åˆæœ¬åœ° Qwen æˆ– OpenAI å…¼å®¹æ¥å£è¿›è¡Œæ£€ç´¢é‡æ’ä¸æ³•å¾‹é—®ç­”ç”Ÿæˆã€‚"
  },
  {
    "objectID": "README-zh.html#åŠŸèƒ½ç‰¹æ€§",
    "href": "README-zh.html#åŠŸèƒ½ç‰¹æ€§",
    "title": "",
    "section": "1 åŠŸèƒ½ç‰¹æ€§",
    "text": "1 åŠŸèƒ½ç‰¹æ€§\n\næ³•æ¡é¢„å¤„ç†ï¼šåŸå§‹æ–‡æœ¬æ¸…æ´—ã€åˆ†æ¡ã€ç»“æ„åŒ–ä¸º JSONL\nè·¯ç”±ï¼š\n\nè§„åˆ™è·¯ç”±è¯†åˆ«ä»»åŠ¡/é—®é¢˜ç±»å‹\nå¯é€‰ LLM è·¯ç”±è¦†ç›–\n\næ··åˆæ£€ç´¢ï¼š\n\nBM25ï¼ˆå…³é”®è¯åŒ¹é…ï¼‰\nDenseï¼ˆBGE + FAISS å‘é‡æ£€ç´¢ï¼‰\nColBERTï¼ˆlate interaction ç²¾æ’é€šé“ï¼‰\nå¤šé€šé“åŠ æƒèåˆ\næŒ‰è¯­è¨€è·¯ç”±ï¼ˆzh/enï¼‰\nRRF + weighted sum èåˆå¤šé€šé“ç»“æœ\nGraphï¼ˆåŸºäºæ³•æ¡å…³ç³»æ‰©å±•å€™é€‰ï¼‰\nRerankerï¼ˆCrossEncoder æˆ– LLM é‡æ’ï¼‰\n\nLLM ç”Ÿæˆï¼š\n\næœ¬åœ° Qwenï¼ˆé»˜è®¤ï¼‰\nå¯é€‰ OpenAI å…¼å®¹æ¥å£\n\næœåŠ¡ä¸ç•Œé¢ï¼š\n\nFastAPI åç«¯ API\nWeb UIï¼ˆå¤šè½®é—®ç­”ã€æ¡æ–‡å±•ç¤ºã€PDF ä¸Šä¼ ï¼‰\n\nè„šæœ¬æ”¯æŒï¼š\n\né¢„å¤„ç† / ç´¢å¼•æ„å»º / æ£€ç´¢è¯„ä¼°"
  },
  {
    "objectID": "README-zh.html#åœ¨çº¿æ¼”ç¤º",
    "href": "README-zh.html#åœ¨çº¿æ¼”ç¤º",
    "title": "",
    "section": "2 åœ¨çº¿æ¼”ç¤º",
    "text": "2 åœ¨çº¿æ¼”ç¤º\nå¯ç›´æ¥è®¿é—® https://huggingface.co/spaces/flora-l/Legal-RAG ï¼ˆåœ¨çº¿ Demoï¼Œæ— éœ€æœ¬åœ°ç¯å¢ƒï¼‰\nè¯´æ˜ï¼š\n\nè¯¥ Hugging Face Space å½“å‰æœªå¯ç”¨ GPUï¼Œå› æ­¤æš‚ä¸æ”¯æŒæœ¬åœ° Qwen æ¨¡å‹æ¨ç†ã€‚\nç”Ÿæˆç­”æ¡ˆéœ€è¦ä½¿ç”¨ OpenAI API Keyã€‚ä½¿ç”¨åï¼Œæ‚¨å¯ä»¥éšæ—¶åœ¨ OpenAI è´¦æˆ·ä¸­æ’¤é”€ OPENAI_API_KEYã€‚\nè¯¥ Spaceä¸€æ®µæ—¶é—´åä¼šè¿›å…¥ä¼‘çœ ã€‚å¦‚éœ€æ¿€æ´»ï¼Œè¯·ç•™è¨€æˆ–å‘issueã€‚"
  },
  {
    "objectID": "README-zh.html#ç³»ç»Ÿæ¶æ„",
    "href": "README-zh.html#ç³»ç»Ÿæ¶æ„",
    "title": "",
    "section": "3 ç³»ç»Ÿæ¶æ„",
    "text": "3 ç³»ç»Ÿæ¶æ„"
  },
  {
    "objectID": "README-zh.html#å¿«é€Ÿå¼€å§‹",
    "href": "README-zh.html#å¿«é€Ÿå¼€å§‹",
    "title": "",
    "section": "4 å¿«é€Ÿå¼€å§‹",
    "text": "4 å¿«é€Ÿå¼€å§‹\n\n1. å…‹éš†é¡¹ç›®å¹¶å®‰è£…ä¾èµ–\ngit clone https://github.com/Fan-Luo/Legal-RAG.git\ncd Legal-RAG\npip install -r requirements.txt\n\n\n2. å‡†å¤‡æ³•å¾‹æ•°æ®å¹¶æ„å»ºç´¢å¼•\næ³•å¾‹æ•°æ®ä½äº data/raw/ï¼Œå¯æ›¿æ¢æˆ–å¢åŠ éœ€è¦çš„å…¶ä»–æ³•å¾‹æ–‡æœ¬ã€‚ é»˜è®¤è¯­æ–™åŒ…å«ï¼š\n\nä¸­æ–‡ï¼šä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nè‹±æ–‡ï¼šUniform Commercial Codeï¼ˆUCCï¼‰\n\nç³»ç»Ÿä¼šæ ¹æ®é—®é¢˜è¯­è¨€è·¯ç”±åˆ°å¯¹åº”è¯­æ–™ä¸ç´¢å¼•ã€‚\n\n# é¢„å¤„ç†ä¸º JSONL\npython -m scripts.preprocess_law\n\n# æ„å»º FAISS + BM25 + ColBERT ç´¢å¼•\npython -m scripts.build_index\n\n# æ„å»º æ³•å¾‹çŸ¥è¯†å›¾è°±\npython -m scripts.build_graph\nç”Ÿæˆçš„è¯­æ–™æŒ‰è¯­è¨€æ‹†åˆ†ï¼š\n\ndata/processed/law_zh.jsonl, data/processed/law_en.jsonl\ndata/index/zh/..., data/index/en/...\ndata/graph/law_graph_zh.jsonl, data/graph/law_graph_en.jsonl\n\n\n\n3. å¯åŠ¨ API æœåŠ¡\npython -m uvicorn legalrag.api.server:app --host 127.0.0.1 --port 8000\n\né»˜è®¤ä½¿ç”¨æœ¬åœ° Qwen æ¨¡å‹ï¼ˆå¦‚ Qwen/Qwen2.5-3B-Instructï¼‰ï¼Œéœ€è¦æœ¬åœ°æœºå™¨æœ‰GPU å’Œè¶³å¤Ÿå†…å­˜ã€‚ å¦‚éœ€ä½¿ç”¨ OpenAIï¼Œè¯·å‚è€ƒ ã€Œåœ¨çº¿æ¼”ç¤ºï¼ˆHugging Face Spacesï¼‰ / OpenAI é…ç½®ã€ã€‚\n\n\n\n4. æ‰“å¼€æ¼”ç¤ºç•Œé¢\nè®¿é—®ï¼šhttp://127.0.0.1:8000/ æˆ– http://127.0.0.1:8000/ui/\næç¤ºï¼š\n\nPDF ä¸Šä¼ å»ºè®®ä½¿ç”¨å¯å¤åˆ¶æ–‡æœ¬çš„ PDFï¼Œä»¥æé«˜è§£æå‡†ç¡®ç‡ã€‚\næœ¬åœ° LLMï¼ˆQwen / BGEï¼‰å»ºè®®ä½¿ç”¨ GPU æˆ–å……è¶³æ˜¾å­˜ï¼›OpenAI API ä¸ºå¯é€‰æ–¹æ¡ˆã€‚"
  },
  {
    "objectID": "README-zh.html#æœåŠ¡æ‹†åˆ†",
    "href": "README-zh.html#æœåŠ¡æ‹†åˆ†",
    "title": "",
    "section": "5 æœåŠ¡æ‹†åˆ†",
    "text": "5 æœåŠ¡æ‹†åˆ†\n\nAPI æœåŠ¡ï¼šlegalrag.api.server:app\næ£€ç´¢æœåŠ¡ï¼šlegalrag.services.retrieval_api:app\nç´¢å¼•ç®¡ç†æœåŠ¡ï¼šlegalrag.services.index_api:app\n\næœ¬åœ°å¤šæœåŠ¡å¯åŠ¨ï¼š\ndocker compose up --build\nç´¢å¼•ç‰ˆæœ¬ç®¡ç†ï¼š\npython scripts/build_index.py --index-version v1 --activate\npython scripts/index_admin.py list\npython scripts/index_admin.py activate v1"
  },
  {
    "objectID": "README-zh.html#ç¤ºä¾‹",
    "href": "README-zh.html#ç¤ºä¾‹",
    "title": "",
    "section": "6 ç¤ºä¾‹",
    "text": "6 ç¤ºä¾‹\nfrom legalrag.config import AppConfig\nfrom legalrag.pipeline.rag_pipeline import RagPipeline\n\ncfg = AppConfig.load(None)\npipeline = RagPipeline(cfg)\n\nquestion = \"åˆåŒç”Ÿæ•ˆåï¼Œå¦‚æœå¯¹ä»·æ¬¾å’Œå±¥è¡Œåœ°ç‚¹æ²¡æœ‰çº¦å®šï¼Œåº”å½“å¦‚ä½•å¤„ç†ï¼Ÿ\"\nans = pipeline.answer(question)\n\nprint(\"Question:\", question)\nprint(\"Answer:\", ans.answer)"
  },
  {
    "objectID": "README-zh.html#é¡¹ç›®ç»“æ„",
    "href": "README-zh.html#é¡¹ç›®ç»“æ„",
    "title": "",
    "section": "7 é¡¹ç›®ç»“æ„",
    "text": "7 é¡¹ç›®ç»“æ„\nLegal-RAG/\nâ”‚\nâ”œâ”€â”€ legalrag/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ config.py                   \nâ”‚   â”œâ”€â”€ schemas.py                 \nâ”‚   â”œâ”€â”€ llm/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ client.py              # Qwen / OpenAI LLMClient \nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ retrieval/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py    # Dense + Sparse + Graph\nâ”‚   â”‚   â”œâ”€â”€ bm25_retriever.py      # Sparse (BM25 + jieba)\nâ”‚   â”‚   â”œâ”€â”€ dense_retriever.py     # Dense (BGE + FAISS)\nâ”‚   â”‚   â”œâ”€â”€ colbert_retriever.py\nâ”‚   â”‚   â”œâ”€â”€ by_lang_retriever.py   # æŒ‰è¯­è¨€è·¯ç”±\nâ”‚   â”‚   â”œâ”€â”€ graph_retriever.py\nâ”‚   â”‚   â”œâ”€â”€ graph_store.py         # law_graph / legal_kg  \nâ”‚   â”‚   â”œâ”€â”€ rerankers.py\nâ”‚   â”‚   â”œâ”€â”€ corpus_loader.py       # read all chunks from processed_dir\nâ”‚   â”‚   â”œâ”€â”€ vector_store.py       \nâ”‚   â”‚   â””â”€â”€ builders\nâ”‚   â”‚       â”œâ”€â”€ __init__.py\nâ”‚   â”‚       â”œâ”€â”€ bm25_builder.py\nâ”‚   â”‚       â”œâ”€â”€ colbert_builder.py\nâ”‚   â”‚       â”œâ”€â”€ faiss_builder.py\nâ”‚   â”‚       â”œâ”€â”€ graph_builder.py\nâ”‚   â”‚       â””â”€â”€ incremental_dense_builder.py\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ routing/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ router.py              # TaskType/IssueType + Mode è·¯ç”±\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ pdf/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ parser.py              # pdfplumber + OCR fallback\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ ingest/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ ingestor.py            # LawChunk JSONL \nâ”‚   â”‚   â”œâ”€â”€ orchestrator.py        # jobs + status\nâ”‚   â”‚   â””â”€â”€ service.py         \nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ pipeline/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ rag_pipeline.py        # Graph-aware RAG æ ¸å¿ƒæ¨ç†é“¾\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ prompts/\nâ”‚   â”‚   â”œâ”€â”€  prompt_en.json        # English Prompt \nâ”‚   â”‚   â””â”€â”€  prompt_zh.json        # Chinese Prompt \nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ utils/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ logger.py              # æ—¥å¿— \nâ”‚   â”‚   â””â”€â”€ text.py                # æ–‡æœ¬æ¸…æ´— / æ­£åˆ™å·¥å…·\nâ”‚   â”‚\nâ”‚   â””â”€â”€ api/\nâ”‚       â”œâ”€â”€ __init__.py\nâ”‚       â””â”€â”€ server.py              # FastAPIï¼ˆ/rag/retrieve, /rag/answer, /ingest/pdfï¼‰\nâ”‚\nâ”œâ”€â”€ ui/\nâ”‚   â”œâ”€â”€ index.qmd\nâ”‚   â””â”€â”€ demo.qmd\nâ”‚\nâ”œâ”€â”€ scripts/\nâ”‚   â”œâ”€â”€ preprocess_law.py          # æ³•æ¡è§£æ â†’ LawChunk JSONL\nâ”‚   â”œâ”€â”€ build_index.py             # FAISS + BM25 ç´¢å¼•æ„å»º\nâ”‚   â”œâ”€â”€ build_graph.py             # law_graph / legal_kg æ„å»º\nâ”‚   â””â”€â”€ evaluate_retrieval.py      # Hit@K / MRR / nDCG\nâ”‚\nâ”œâ”€â”€ notebooks/\nâ”‚   â”œâ”€â”€ 01_Launch_the_UI.ipynb\nâ”‚   â”œâ”€â”€ 02_LegalRAG_Pipeline.ipynb\nâ”‚   â”œâ”€â”€ 03_Retrieval_Performance_Evaluation.ipynb\nâ”‚   â””â”€â”€ 04_Law_Graph_Visualization.ipynb\nâ”‚\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/                         \nâ”‚   â”‚   â”œâ”€â”€ minfadian.txt            \nâ”‚   â”‚   â””â”€â”€ ucc/                    \nâ”‚   â”œâ”€â”€ processed/                 # law_zh.jsonl / law_en.jsonl\nâ”‚   â”œâ”€â”€ index/                     # faiss/bm25/colbert per language\nâ”‚   â””â”€â”€ graph/                     # law_graph_zh.jsonl / law_graph_en.jsonl\nâ”‚   â””â”€â”€ eval/\nâ”‚       â””â”€â”€ law_qa.jsonl\nâ”‚\nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ architecture.mmd\nâ”‚   â””â”€â”€ architecture.png\nâ”‚\nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ test_router.py\nâ”‚   â””â”€â”€ test_retrieval.py\nâ”‚\nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ README-zh.md\nâ”œâ”€â”€ LICENSE\nâ”œâ”€â”€ pyproject.toml\nâ”œâ”€â”€ requirements.txt\nâ”œâ”€â”€ app.py                           # Hugging Face Space å…¥å£\nâ”œâ”€â”€ Dockerfile\nâ””â”€â”€ .gitignore"
  },
  {
    "objectID": "README-zh.html#å¯æ‰©å±•æ–¹å‘",
    "href": "README-zh.html#å¯æ‰©å±•æ–¹å‘",
    "title": "",
    "section": "8 å¯æ‰©å±•æ–¹å‘",
    "text": "8 å¯æ‰©å±•æ–¹å‘\n\næ›´å¤æ‚çš„æ³•å¾‹çŸ¥è¯†å›¾è°±\né«˜çº§æŸ¥è¯¢è·¯ç”± / å¤šæ¨¡å‹èåˆ\næ”¯æŒå…¶ä»–æ³•å¾‹é¢†åŸŸæˆ–å¤šè¯­ç§"
  },
  {
    "objectID": "README-zh.html#è®¸å¯å£°æ˜",
    "href": "README-zh.html#è®¸å¯å£°æ˜",
    "title": "",
    "section": "9 è®¸å¯å£°æ˜",
    "text": "9 è®¸å¯å£°æ˜\nApache License 2.0\næœ¬ä»“åº“ä»…åŒ…å«æºç ï¼Œä¸åŒ…å«ç¬¬ä¸‰æ–¹æ¨¡å‹æƒé‡ã€‚ç”¨æˆ·éœ€è‡ªè¡Œéµå®ˆæ‰€ä½¿ç”¨æ¨¡å‹çš„è®¸å¯è¯ï¼ˆå¦‚ Qwenã€BGEã€OpenAI ç­‰ï¼‰ã€‚"
  },
  {
    "objectID": "README-zh.html#å…è´£å£°æ˜",
    "href": "README-zh.html#å…è´£å£°æ˜",
    "title": "",
    "section": "10 å…è´£å£°æ˜",
    "text": "10 å…è´£å£°æ˜\næœ¬é¡¹ç›®ä»…ç”¨äºæä¾›æ³•å¾‹ä¿¡æ¯è¾…åŠ©ï¼Œä¾›å­¦ä¹ ä¸ç ”ç©¶å‚è€ƒä¹‹ç”¨ã€‚ ä½¿ç”¨è€…ä¸åº”å°†æœ¬é¡¹ç›®ä½œä¸ºä¸“ä¸šæ³•å¾‹å’¨è¯¢çš„æ›¿ä»£ï¼Œå› ä½¿ç”¨æœ¬é¡¹ç›®æ‰€äº§ç”Ÿçš„ä»»ä½•ç›´æ¥æˆ–é—´æ¥åæœï¼Œé¡¹ç›®ä½œè€…åŠè´¡çŒ®è€…ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚"
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html",
    "href": "notebooks/02_LegalRAG_Pipeline.html",
    "title": "Run LegalRAG Pipeline",
    "section": "",
    "text": "This notebook demonstrates the end-to-end behavior of the Legal RAG system, covering data preprocessing, query understanding, routing, hybrid retrieval, and evidence-backed response generation."
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html#repository-install",
    "href": "notebooks/02_LegalRAG_Pipeline.html#repository-install",
    "title": "Run LegalRAG Pipeline",
    "section": "1 Repository Install",
    "text": "1 Repository Install\nFirst, pull the project source code and initialize the execution environment.\ngit clone https://github.com/Fan-Luo/Legal-RAG.git\ncd Legal-RAG\npip install -e ."
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html#data-preprocess",
    "href": "notebooks/02_LegalRAG_Pipeline.html#data-preprocess",
    "title": "Run LegalRAG Pipeline",
    "section": "2 Data preprocess",
    "text": "2 Data preprocess\nBefore the LegalRAG pipeline can serve queries, the legal corpus must be transformed into structured, searchable representations.\nIn the offline preprocessing stage, raw legal texts are converted into normalized data artifacts, retrieval indices, and a legal knowledge graph through the following steps:\n\nPreprocess law files\nRaw legal documents are parsed, cleaned, and normalized into a unified JSONL format. Each legal provision is assigned a stable identifier and enriched with structural metadata such as law name, part, chapter, article number, and source file.\npython -m scripts.preprocess_law\nBuild retrieval indices\nMultiple complementary retrieval indices are constructed to support lexical, dense, and late-interaction search paradigms:\n\nBM25 for sparse keyword-based retrieval\nFAISS for dense vector similarity search\nColBERT for token-level late interaction retrieval\n\npython -m scripts.build_index\nConstruct the legal knowledge graph\nLegal articles are connected via structured relationships (e.g., citation, reference, dependency), forming a directed legal knowledge graph that enables graph-based expansion and contextual reasoning.\npython -m scripts.build_graph\n\nGenerated Data Artifacts:\n\n\n\n    \n\n\n\n\n\n\nLang\nCategory\nPath\nExists\nSize (MB)\n\n\n\n\n11\nen\nGraph\ndata/graph/law_graph_en.jsonl\nTrue\n0.228\n\n\n3\nen\nIndex\ndata/index/en/bm25.pkl\nTrue\n1.796\n\n\n9\nen\nIndex\ndata/index/en/colbert/colbert_meta.jsonl\nTrue\n0.987\n\n\n5\nen\nIndex\ndata/index/en/faiss/faiss.index\nTrue\n1.884\n\n\n7\nen\nIndex\ndata/index/en/faiss/faiss_meta.jsonl\nTrue\n0.962\n\n\n1\nen\nProcessed\ndata/processed/law_en.jsonl\nTrue\n0.982\n\n\n10\nzh\nGraph\ndata/graph/law_graph_zh.jsonl\nTrue\n0.405\n\n\n2\nzh\nIndex\ndata/index/zh/bm25.pkl\nTrue\n0.992\n\n\n8\nzh\nIndex\ndata/index/zh/colbert/colbert_meta.jsonl\nTrue\n0.654\n\n\n4\nzh\nIndex\ndata/index/zh/faiss/faiss.index\nTrue\n4.018\n\n\n6\nzh\nIndex\ndata/index/zh/faiss/faiss_meta.jsonl\nTrue\n0.601\n\n\n0\nzh\nProcessed\ndata/processed/law_zh.jsonl\nTrue\n0.658\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n  \n    \n    \n\n  \n    \n  \n    \n    \n  \n\n    \n  \n\n\nExample entries from law_zh.jsonl and law_en.jsonl:\n\n\n\n    \n\n\n\n\n\n\nid\nlaw_name\nlang\narticle_no\narticle_id\ntext\nsource\n\n\n\n\n0\nminfadian.txt::ä¸€\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nzh\nç¬¬ä¸€æ¡\n1\nç¬¬ä¸€æ¡ ä¸ºäº†ä¿æŠ¤æ°‘äº‹ä¸»ä½“çš„åˆæ³•æƒç›Šï¼Œè°ƒæ•´æ°‘äº‹å…³ç³»ï¼Œç»´æŠ¤ç¤¾ä¼šå’Œç»æµç§©åºï¼Œé€‚åº”ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰å‘...\nminfadian.txt\n\n\n1\nminfadian.txt::äºŒ\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nzh\nç¬¬äºŒæ¡\n2\nç¬¬äºŒæ¡ æ°‘æ³•è°ƒæ•´å¹³ç­‰ä¸»ä½“çš„è‡ªç„¶äººã€æ³•äººå’Œéæ³•äººç»„ç»‡ä¹‹é—´çš„äººèº«å…³ç³»å’Œè´¢äº§å…³ç³»ã€‚\nminfadian.txt\n\n\n2\nminfadian.txt::ä¸‰\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nzh\nç¬¬ä¸‰æ¡\n3\nç¬¬ä¸‰æ¡ æ°‘äº‹ä¸»ä½“çš„äººèº«æƒåˆ©ã€è´¢äº§æƒåˆ©ä»¥åŠå…¶ä»–åˆæ³•æƒç›Šå—æ³•å¾‹ä¿æŠ¤ï¼Œä»»ä½•ç»„ç»‡æˆ–è€…ä¸ªäººä¸å¾—ä¾µçŠ¯ã€‚\nminfadian.txt\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n  \n\n\n\n    \n\n\n\n\n\n\nid\nlaw_name\nlang\narticle_no\narticle_id\ntext\nsource\n\n\n\n\n0\nucc_1.txt::1-101\nUniform Commercial Code\nen\nÂ§ 1-101\n1-101\nÂ§ 1-101. Short Titles.(a) This [Act] may be ci...\nucc_1.txt\n\n\n1\nucc_1.txt::1-102\nUniform Commercial Code\nen\nÂ§ 1-102\n1-102\nÂ§ 1-102. Scope of Article.This article applies...\nucc_1.txt\n\n\n2\nucc_1.txt::1-103\nUniform Commercial Code\nen\nÂ§ 1-103\n1-103\nÂ§ 1-103. Construction of Uniform Commercial Co...\nucc_1.txt\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n  \n\n\n\n\n\nField\nDescription\n\n\n\n\nid\nInternal numeric identifier\n\n\nlaw_name\nName of the law\n\n\nlang\nLanguage of the law article\n\n\narticle_no\nArticle number (human-readable)\n\n\narticle_id\nStable article identifier\n\n\ntext\nFull article text\n\n\nsource\nOriginal source file"
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html#initialize-the-rag-pipeline",
    "href": "notebooks/02_LegalRAG_Pipeline.html#initialize-the-rag-pipeline",
    "title": "Run LegalRAG Pipeline",
    "section": "3 Initialize the RAG pipeline",
    "text": "3 Initialize the RAG pipeline\nThis section sets up the RAG pipeline and configures the underlying language model. The pipeline is constructed from a centralized configuration, ensuring that retrieval, ranking, and generation components are consistently parameterized.\n\nfrom legalrag.pipeline.rag_pipeline import RagPipeline\nfrom legalrag.config import AppConfig\n\ncfg = AppConfig.load(None)\ncfg.llm.provider = \"qwen-local\"\ncfg.llm.model = \"Qwen/Qwen2.5-3B-Instruct\"\npipeline = RagPipeline(cfg)\n\nThe default configuration uses local Qwen model as the generation model by default, and it can be switched to an OpenAI model:\ncfg.llm.provider = \"openai\"\ncfg.llm.model = \"gpt-4.1-mini\"   \n# Requires setting OPENAI_API_KEY in environment variables"
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html#query-understanding-and-routing",
    "href": "notebooks/02_LegalRAG_Pipeline.html#query-understanding-and-routing",
    "title": "Run LegalRAG Pipeline",
    "section": "4 Query Understanding and Routing",
    "text": "4 Query Understanding and Routing\nThis step distinguishes between different query types and selects a retrieval mode accordingly.\nAccurate query understanding is critical, as it directly influences downstream retrieval strategies and answer generation behavior.\n\nfrom legalrag.routing.router import QueryRouter\nfrom legalrag.llm.client import LLMClient\n\nllm = LLMClient.from_config(cfg)\nrouter = QueryRouter(llm_client=llm, llm_based=cfg.routing.llm_based)\nquestion = 'å·²ç»æœ‰ä¸¤ä¸ªäº²ç”Ÿå­©å­çš„å®¶åº­å¯ä»¥å†æ”¶å…»ä¸€ä¸ªå­©å­å—?'\ndecision = router.route(question)\nprint('Issue Type: ', decision.issue_type)\nprint('Task Type: ', decision.task_type)\nprint('mode: ', decision.mode)\n\nIssue Type:  IssueType.MARRIAGE_FAMILY\nTask Type:  TaskType.JUDGE_STYLE\nmode:  RoutingMode.RAG"
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html#retrieve-legal-provisions",
    "href": "notebooks/02_LegalRAG_Pipeline.html#retrieve-legal-provisions",
    "title": "Run LegalRAG Pipeline",
    "section": "5 Retrieve legal provisions",
    "text": "5 Retrieve legal provisions\nIn this stage, the system retrieves candidate legal provisions relevant to the query.\nLegalRAG uses a multi-channel retrieval strategy that combines dense semantic search, sparse lexical matching, and late-interaction models. Depending on the retrieval mode inferred during query understanding, a graph-based enhancement stage may be applied to expand the candidate set with structurally related legal provisions. Final ranking is refined using cross-encoder or LLM-based reranking.\n\nquestion = 'å·²ç»æœ‰ä¸¤ä¸ªäº²ç”Ÿå­©å­çš„å®¶åº­å¯ä»¥å†æ”¶å…»ä¸€ä¸ªå­©å­å—?'\n_, hits, _ = pipeline.retrieve(question, llm, top_k=10, decision=decision)\nhits_to_dataframe(hits)\n\n\n    \n\n\n\n\n\n\nscore\nchannel\narticle_id\npreview\n\n\n\n\n0\n1.04\n[dense, colbert, bm25]\n1100\nç¬¬ä¸€åƒä¸€ç™¾æ¡ æ— å­å¥³çš„æ”¶å…»äººå¯ä»¥æ”¶å…»ä¸¤åå­å¥³ï¼›æœ‰å­å¥³çš„æ”¶å…»äººåªèƒ½æ”¶å…»ä¸€åå­å¥³ã€‚ æ”¶å…»å­¤å„¿ã€æ®‹ç–¾æœªæˆå¹´äººæˆ–è€…å„¿ç«¥ç¦åˆ©æœºæ„æŠšå…»çš„æŸ¥æ‰¾ä¸åˆ°ç”Ÿçˆ¶æ¯çš„æœªæˆå¹´äººï¼Œå¯ä»¥ä¸å—å‰æ¬¾å’Œæœ¬æ³•ç¬¬ä¸€åƒé›¶ä¹åå…«æ¡ç¬¬ä¸€é¡¹è§„å®šçš„é™åˆ¶ã€‚...\n\n\n1\n0.67\n[dense, colbert]\n1103\nç¬¬ä¸€åƒä¸€ç™¾é›¶ä¸‰æ¡ ç»§çˆ¶æˆ–è€…ç»§æ¯ç»ç»§å­å¥³çš„ç”Ÿçˆ¶æ¯åŒæ„ï¼Œå¯ä»¥æ”¶å…»ç»§å­å¥³ï¼Œå¹¶å¯ä»¥ä¸å—æœ¬æ³•ç¬¬ä¸€åƒé›¶ä¹åä¸‰æ¡ç¬¬ä¸‰é¡¹ã€...\n\n\n2\n0.55\n[dense, colbert]\n1099\nç¬¬ä¸€åƒé›¶ä¹åä¹æ¡ æ”¶å…»ä¸‰ä»£ä»¥å†…æ—ç³»åŒè¾ˆè¡€äº²çš„å­å¥³ï¼Œå¯ä»¥ä¸å—æœ¬æ³•ç¬¬ä¸€åƒé›¶ä¹åä¸‰æ¡ç¬¬ä¸‰é¡¹ã€...\n\n\n3\n0.40\n[dense, bm25]\n1101\nç¬¬ä¸€åƒä¸€ç™¾é›¶ä¸€æ¡ æœ‰é…å¶è€…æ”¶å…»å­å¥³ï¼Œåº”å½“å¤«å¦»å…±åŒæ”¶å…»ã€‚...\n\n\n4\n0.31\n[bm25, colbert]\n699\nç¬¬å…­ç™¾ä¹åä¹æ¡ åŒä¸€å€ºåŠ¡æœ‰ä¸¤ä¸ªä»¥ä¸Šä¿è¯äººçš„ï¼Œä¿è¯äººåº”å½“æŒ‰ç…§ä¿è¯åˆåŒçº¦å®šçš„ä¿è¯ä»½é¢ï¼Œæ‰¿æ‹…ä¿è¯è´£ä»»ï¼›æ²¡æœ‰çº¦å®šä¿è¯ä»½é¢çš„ï¼Œå€ºæƒäººå¯ä»¥è¯·æ±‚ä»»ä½•ä¸€ä¸ªä¿è¯äººåœ¨å…¶ä¿è¯èŒƒå›´å†…æ‰¿æ‹…ä¿è¯è´£ä»»ã€‚...\n\n\n5\n0.31\n[dense, colbert]\n1117\nç¬¬ä¸€åƒä¸€ç™¾ä¸€åä¸ƒæ¡ æ”¶å…»å…³ç³»è§£é™¤åï¼Œå…»å­å¥³ä¸å…»çˆ¶æ¯ä»¥åŠå…¶ä»–è¿‘äº²å±é—´çš„æƒåˆ©ä¹‰åŠ¡å…³ç³»å³è¡Œæ¶ˆé™¤ï¼Œä¸ç”Ÿçˆ¶æ¯ä»¥åŠå…¶ä»–è¿‘äº²å±é—´çš„æƒåˆ©ä¹‰åŠ¡å…³ç³»è‡ªè¡Œæ¢å¤ã€‚ä½†æ˜¯ï¼Œæˆå¹´å…»å­å¥³ä¸ç”Ÿçˆ¶æ¯ä»¥åŠå…¶ä»–è¿‘äº²å±é—´çš„æƒåˆ©ä¹‰åŠ¡å…³ç³»æ˜¯å¦æ¢å¤ï¼Œå¯ä»¥åå•†ç¡®å®šã€‚...\n\n\n6\n0.26\n[colbert, dense]\n1098\nç¬¬ä¸€åƒé›¶ä¹åå…«æ¡ æ”¶å…»äººåº”å½“åŒæ—¶å…·å¤‡ä¸‹åˆ—æ¡ä»¶ï¼š ï¼ˆä¸€ï¼‰æ— å­å¥³æˆ–è€…åªæœ‰ä¸€åå­å¥³ï¼› ï¼ˆäºŒï¼‰æœ‰æŠšå…»ã€æ•™è‚²å’Œä¿æŠ¤è¢«æ”¶å…»äººçš„èƒ½åŠ›ï¼› ï¼ˆä¸‰ï¼‰æœªæ‚£æœ‰åœ¨åŒ»å­¦ä¸Šè®¤ä¸ºä¸åº”å½“æ”¶å…»å­å¥³çš„ç–¾ç—…ï¼› ï¼ˆå››ï¼‰æ— ä¸åˆ©äºè¢«æ”¶å…»äººå¥åº·æˆé•¿çš„è¿æ³•çŠ¯ç½ªè®°å½•ï¼› ï¼ˆäº”ï¼‰å¹´æ»¡ä¸‰åå‘¨å²ã€‚...\n\n\n7\n0.23\n[dense, colbert]\n1097\nç¬¬ä¸€åƒé›¶ä¹åä¸ƒæ¡ ç”Ÿçˆ¶æ¯é€å…»å­å¥³ï¼Œåº”å½“åŒæ–¹å…±åŒé€å…»ã€‚ç”Ÿçˆ¶æ¯ä¸€æ–¹ä¸æ˜æˆ–è€…æŸ¥æ‰¾ä¸åˆ°çš„ï¼Œå¯ä»¥å•æ–¹é€å…»ã€‚...\n\n\n8\n0.23\n[bm25, colbert]\n1105\nç¬¬ä¸€åƒä¸€ç™¾é›¶äº”æ¡ æ”¶å…»åº”å½“å‘å¿çº§ä»¥ä¸Šäººæ°‘æ”¿åºœæ°‘æ”¿éƒ¨é—¨ç™»è®°ã€‚æ”¶å…»å…³ç³»è‡ªç™»è®°ä¹‹æ—¥èµ·æˆç«‹ã€‚ æ”¶å…»æŸ¥æ‰¾ä¸åˆ°ç”Ÿçˆ¶æ¯çš„æœªæˆå¹´äººçš„ï¼ŒåŠç†ç™»è®°çš„æ°‘æ”¿éƒ¨é—¨åº”å½“åœ¨ç™»è®°å‰äºˆä»¥å…¬å‘Šã€‚ æ”¶å…»å…³ç³»å½“äº‹äººæ„¿æ„ç­¾è®¢æ”¶å…»åè®®çš„ï¼Œå¯ä»¥ç­¾è®¢æ”¶å…»åè®®ã€‚ æ”¶å…»å…³ç³»å½“äº‹äººå„æ–¹æˆ–è€…ä¸€æ–¹è¦æ±‚åŠç†æ”¶å…»å…¬è¯çš„ï¼Œåº”å½“åŠç†æ”¶å…»å…¬è¯ã€‚ å¿çº§ä»¥ä¸Šäººæ°‘æ”¿åºœæ°‘æ”¿...\n\n\n9\n0.18\n[bm25, colbert]\n1114\nç¬¬ä¸€åƒä¸€ç™¾ä¸€åå››æ¡ æ”¶å…»äººåœ¨è¢«æ”¶å…»äººæˆå¹´ä»¥å‰ï¼Œä¸å¾—è§£é™¤æ”¶å…»å…³ç³»ï¼Œä½†æ˜¯æ”¶å…»äººã€é€å…»äººåŒæ–¹åè®®è§£é™¤çš„é™¤å¤–ã€‚å…»å­å¥³å…«å‘¨å²ä»¥ä¸Šçš„ï¼Œåº”å½“å¾å¾—æœ¬äººåŒæ„ã€‚ æ”¶å…»äººä¸å±¥è¡ŒæŠšå…»ä¹‰åŠ¡ï¼Œæœ‰è™å¾…ã€é—å¼ƒç­‰ä¾µå®³æœªæˆå¹´å…»å­å¥³åˆæ³•æƒç›Šè¡Œä¸ºçš„ï¼Œé€å…»äººæœ‰æƒè¦æ±‚è§£é™¤å…»çˆ¶æ¯ä¸å…»å­å¥³é—´çš„æ”¶å…»å…³ç³»ã€‚é€å…»äººã€æ”¶å…»äººä¸èƒ½è¾¾æˆè§£é™¤æ”¶å…»å…³ç³»åè®®çš„ï¼Œå¯...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n  \n\n\n\nquestion = 'What standards must goods satisfy to be merchantableï¼Ÿ'\n_, hits, _ = pipeline.retrieve(question, llm, top_k=10, decision=decision)\nhits_to_dataframe(hits)\n\n\n\n\n\n    \n\n\n\n\n\n\nscore\nchannel\narticle_id\npreview\n\n\n\n\n0\n1.07\n[dense, bm25, colbert]\n2A-212\nÂ§ 2A-212. IMPLIED WARRANTY OF MERCHANTABILITY. (1) Except in afinance lease, a warranty that the goods will be merchantable is implied in alease contrac...\n\n\n1\n1.01\n[dense, colbert, bm25]\n2-314\nÂ§ 2-314. Implied Warranty: Merchantability; Usage of Trade. (1) Unless excluded or modified (Section2-316), a warranty that the goods shall be merchanta...\n\n\n2\n0.34\n[dense, colbert]\n2A-511\nÂ§ 2A-511. MERCHANT LESSEE's DUTIES AS TO RIGHTFULLY REJECTED GOODS. (1) Subject to any security interest of a lessee (Section2A-508(5)), if a lessoror as...\n\n\n3\n0.34\n[bm25, colbert]\n2-105\nÂ§ 2-105. Definitions: Transferability; \"Goods\"; \"Future\" Goods; \"Lot\"; \"Commercial Unit\". (1)\"Goods\" means all things (including specially manufacture...\n\n\n4\n0.33\n[dense, colbert]\n2-603\nÂ§ 2-603. Merchant Buyer's Duties as to Rightfully Rejected Goods. (1) Subject to any security interest in the buyer (subsection (3) of Section2-711), wh...\n\n\n5\n0.18\n[colbert, dense]\n7-207\nÂ§ 7-207. Goods Must Be Kept Separate; Fungible Goods.(a) Unless the warehouse receipt provides otherwise, a warehouse shall keep separate the goods covere...\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n    \n  \n\n\nThe result shows how different retrieval signals contributed to the final ranking for debugging, evaluation, and trust in legal AI systems."
  },
  {
    "objectID": "notebooks/02_LegalRAG_Pipeline.html#answer-legal-questions",
    "href": "notebooks/02_LegalRAG_Pipeline.html#answer-legal-questions",
    "title": "Run LegalRAG Pipeline",
    "section": "6 Answer legal questions",
    "text": "6 Answer legal questions\nUsing the retrieved provisions as evidence, the system generates a final answer.\nAnswer generation is explicitly grounded in the retrieved legal texts, ensuring that conclusions are traceable to authoritative sources.\n\n\nQuestion 1: å·²ç»æœ‰ä¸¤ä¸ªå­©å­çš„å®¶åº­å¯ä»¥å†æ”¶å…»ä¸€ä¸ªå­©å­å—?\nquestion = 'å·²ç»æœ‰ä¸¤ä¸ªå­©å­çš„å®¶åº­å¯ä»¥å†æ”¶å…»ä¸€ä¸ªå­©å­å—?'\nanswer = pipeline.answer(question).answer\nrender_legal_json_md(json.loads(answer))\n\n\nç»“è®º\n\nå·²æœ‰ä¸¤ä¸ªå­©å­çš„å®¶åº­ä¸å¯ä»¥å†æ”¶å…»ä¸€ä¸ªå­©å­ã€‚\n\nåˆ†æè®ºè¯\n\nç¬¬ä¸€åƒä¸€ç™¾æ¡ æ— å­å¥³çš„æ”¶å…»äººå¯ä»¥æ”¶å…»ä¸¤åå­å¥³ï¼›æœ‰å­å¥³çš„æ”¶å…»äººåªèƒ½æ”¶å…»ä¸€åå­å¥³ã€‚\n\n\næ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸ã€‹ç¬¬ä¸€ç™¾ä¸€ç™¾æ¡è§„å®šï¼Œå·²å©šäººå£«å³ä½¿æœ‰ä¸¤ä¸ªå­©å­ä¹Ÿä¸èƒ½å†æ”¶å…»å¦ä¸€ä¸ªå­©å­ã€‚\n\nå‚è€ƒæ³•æ¡\n\næ°‘æ³•å…¸ Â· ç¬¬ã€Œ1100ã€æ¡\n\n\n\n\n\nQuestion 2: What standards must goods satisfy to be merchantableï¼Ÿ\nquestion = 'What standards must goods satisfy to be merchantableï¼Ÿ'\nanswer = pipeline.answer(question).answer\nrender_legal_json_md(json.loads(answer))\n\n\nConclusion\n\nThe goods must meet the criteria outlined in the Uniform Commercial Code to be considered merchantable.\n\nReasoning\n\nExcept in a finance lease, a warranty that the goods will be merchantable is implied in a lease contract if the lessor is a merchant with respect to goods of that kind.\n\n\nFor goods to be merchantable according to the Uniform Commercial Code, the lessor must be deemed a merchant concerning the type of goods involved.\n\n\n(a) Pass without objection in the trade under the description in the lease agreement;\n\n\nGoods are considered merchantable if they pass inspection without objections during trading under the agreed-upon description.\n\n\n(b) In the case of fungible goods, are of fair average quality within the description;\n\n\nFungible goods are deemed merchantable if they maintain fair average quality relative to the described standard.\n\n\n(c) Are fit for the ordinary purposes for which goods of that type are used;\n\n\nMerchantable goods must fulfill the typical uses intended for goods of their type.\n\n\n(d) Run, within the variation permitted by the lease agreement, of even kind, quality, and quantity within each unit and among all units involved;\n\n\nEach unit and all units of the goods must adhere to the specified variance limits set forth in the lease agreement.\n\n\n(e) Are adequately contained, packaged, and labeled as the lease agreement may require;\n\n\nThe goods must be properly stored, packed, and labeled in accordance with the lease agreement.\n\n\n(f) Conform to any promises or affirmations of fact made on the container or label;\n\n\nThe goods must comply with any explicit representations about the product on its packaging or labels.\n\nReferenced Provisions\n\nUniform Commercial Code Â· 2A-212"
  },
  {
    "objectID": "notebooks/03_Retrieval_Performance_Evaluation.html",
    "href": "notebooks/03_Retrieval_Performance_Evaluation.html",
    "title": "Retrieval Performance Evaluation",
    "section": "",
    "text": "This notebook focuses on the systematic evaluation of retrieval performance. It proceeds in three stages:"
  },
  {
    "objectID": "notebooks/03_Retrieval_Performance_Evaluation.html#generate-synthetic-evaluation-dataset",
    "href": "notebooks/03_Retrieval_Performance_Evaluation.html#generate-synthetic-evaluation-dataset",
    "title": "Retrieval Performance Evaluation",
    "section": "1 Generate Synthetic Evaluation Dataset",
    "text": "1 Generate Synthetic Evaluation Dataset\nEvaluating legal retrievers requires ground truth dataset with questionâ€“reference article pairs.\nGenerates synthetic legal questions by transforming legal corpus into natural-language queries makes it possible to evaluate retrieval behavior at scale.\n\n\nLoad the law corpus and sample an example\ncorpus = Path(cfg.paths.law_jsonl)\nchunks = [json.loads(l) for l in corpus.open(\"r\", encoding=\"utf-8\") if l.strip()]\ndf_chunks = pd.DataFrame(chunks)\n\nprint(\"Example law chunk:\", )\ndisplay(df_chunks.drop(columns=[\"subpart\", \"section\", \"article_key\", \"source\"]).sample(1, random_state=1))\nprint(\"Number of law chunks:\", len(df_chunks))\n\n\nExample law chunk:\n\n\n\n\n\n\n\n\n\nid\nlaw_name\npart\nchapter\narticle_no\narticle_id\ntext\n\n\n\n\n1179\nminfadian.txt::ä¸€åƒä¸€ç™¾å…«å\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nä¸ƒç¼– ä¾µæƒè´£ä»»\näºŒç«  æŸå®³èµ”å¿\nç¬¬ä¸€åƒä¸€ç™¾å…«åæ¡\n1180\nç¬¬ä¸€åƒä¸€ç™¾å…«åæ¡ å› åŒä¸€ä¾µæƒè¡Œä¸ºé€ æˆå¤šäººæ­»äº¡çš„ï¼Œå¯ä»¥ä»¥ç›¸åŒæ•°é¢ç¡®å®šæ­»äº¡èµ”å¿é‡‘ã€‚\n\n\n\n\n\n\n\nNumber of law chunks: 1260\n\n\n\n\nGenerate synthetic ground-truth legal queryâ€“evidence evaluation dataset\nfrom scripts.generate_synthetic_data import build_ground_truth_queries\n\ndf_queries = build_ground_truth_queries(\n    df_chunks,\n    per_article=2,\n    max_articles=200,\n    total_queries=150,\n    logger=logger,\n    zh_ratio=0.9,\n    generator_llm=llm,\n    judge_llm=llm,\n    embedding_model=embedding_model\n)\n\ndf_sample = df_queries.sample(5, random_state=1)\ndisplay(df_sample.drop(columns=[\"lang\", \"round\", \"rewritten\", \"score\"]))\nprint(\"Generated queries count:\", len(df_queries))\n\n\nGenerated queries count: 150\n\n\n\n\n\n\n\n\n\nquery\nrole\nlaw_name\narticle_no\narticle_id\n\n\n\n\n14\nå¬èµ·æ¥æŒºå¤æ‚çš„ï¼Œé‚£å¦‚æœæˆ‘åœ¨ç­¾ç½²åˆåŒæ—¶å·²ç»æ„è¯†åˆ°è¿™äº›é£é™©äº†ï¼Œæ˜¯å¦è¿˜èƒ½è¦æ±‚èµ”å¿æŸå¤±ï¼Ÿ\nuser\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nç¬¬ä¸ƒç™¾ä¸‰åå…«æ¡\n738\n\n\n98\næœ€åä¸€ä¸ªé—®é¢˜äº†ï¼Œè¿™ä¸ªè§„å®šé€‚ç”¨äºæ‰€æœ‰çš„æŠ€æœ¯å’¨è¯¢æœåŠ¡åˆåŒå—ï¼Ÿ\nuser\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nç¬¬å…«ç™¾å…«åæ¡\n880\n\n\n75\nè®¤è´­ä¹¦æˆ–è€…è®¢è´­ä¹¦ç­‰æ˜¯å¦å±äºé¢„çº¦åˆåŒï¼Ÿ\nuser\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nç¬¬å››ç™¾ä¹åäº”æ¡\n495\n\n\n16\nWhen all parties sign, seal, or affix their fi...\ninhouse\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nç¬¬å››ç™¾ä¹åä¸‰æ¡\n493\n\n\n131\nå½“åˆåŒæ— æ•ˆæ˜¯ç”±äºæ‰¿ç§Ÿäººçš„ä¸å½“è¡Œä¸ºå¼•èµ·æ—¶ï¼Œç§Ÿèµç‰©çš„æ‰€æœ‰æƒå½’è°ï¼Œæ‰¿ç§Ÿäººéœ€ä¸éœ€è¦å‘å‡ºç§Ÿäººè¿›è¡Œç»æµè¡¥å¿ï¼Ÿ\nlawyer\nä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\nç¬¬ä¸ƒç™¾å…­åæ¡\n760"
  },
  {
    "objectID": "notebooks/03_Retrieval_Performance_Evaluation.html#illustrate-multi-channel-multi-stage-retrieval",
    "href": "notebooks/03_Retrieval_Performance_Evaluation.html#illustrate-multi-channel-multi-stage-retrieval",
    "title": "Retrieval Performance Evaluation",
    "section": "2 Illustrate Multi-channel Multi-stage Retrieval",
    "text": "2 Illustrate Multi-channel Multi-stage Retrieval\nThe retrieval pipeline in Legal-RAG is designed as a multi-stage, hybrid, and graph-aware process, balancing recall, precision, and interpretability. Rather than relying on a single retrieval signal, the retriever progressively refines candidates through multi-channel coarse retrieval, score fusion, graph expansion, and reranking.\n\n\nSample a synthetic query to illustrate the retrieval pipeline\nsample = df_sample[[\"query\", \"article_id\"]].sample(1)\ndisplay(sample)\nquestion = sample[\"query\"].values[0]\n\n\n\n\n\n\n\n\n\nquery\narticle_id\n\n\n\n\n75\nè®¤è´­ä¹¦æˆ–è€…è®¢è´­ä¹¦ç­‰æ˜¯å¦å±äºé¢„çº¦åˆåŒï¼Ÿ\n495\n\n\n\n\n\n\n\n\nSparse lexical retrieval\nSparse lexical retrieval (BM25) preserves keyword and statutory phrase matching, performing pure text-based retrieval.\n\n\n\n\n\n\n\n\n\nscore\narticle_id\nchapter\npreview\n\n\n\n\n0\n37.36\n495\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åäº”æ¡ å½“äº‹äººçº¦å®šåœ¨å°†æ¥ä¸€å®šæœŸé™å†…è®¢ç«‹åˆåŒçš„è®¤è´­ä¹¦ã€è®¢è´­ä¹¦ã€é¢„è®¢ä¹¦ç­‰ï¼Œæ„æˆé¢„çº¦åˆåŒã€‚...\n\n\n1\n8.09\n1134\nä¸‰ç«  é—å˜±ç»§æ‰¿å’Œé—èµ \nç¬¬ä¸€åƒä¸€ç™¾ä¸‰åå››æ¡ è‡ªä¹¦é—å˜±ç”±é—å˜±äººäº²ç¬”ä¹¦å†™ï¼Œç­¾åï¼Œæ³¨æ˜å¹´ã€æœˆã€æ—¥ã€‚...\n\n\n2\n7.53\n501\nä¸‰ç«  åˆåŒçš„æ•ˆåŠ›\nç¬¬äº”ç™¾é›¶ä¸€æ¡ å½“äº‹äººåœ¨è®¢ç«‹åˆåŒè¿‡ç¨‹ä¸­çŸ¥æ‚‰çš„å•†ä¸šç§˜å¯†æˆ–è€…å…¶ä»–åº”å½“ä¿å¯†çš„ä¿¡æ¯ï¼Œæ— è®ºåˆåŒæ˜¯å¦æˆç«‹ï¼Œ...\n\n\n3\n7.47\n250\näº”ç«  å›½å®¶æ‰€æœ‰æƒå’Œé›†ä½“æ‰€æœ‰æƒã€ç§äººæ‰€æœ‰æƒ\nç¬¬äºŒç™¾äº”åæ¡ æ£®æ—ã€å±±å²­ã€è‰åŸã€è’åœ°ã€æ»©æ¶‚ç­‰è‡ªç„¶èµ„æºï¼Œå±äºå›½å®¶æ‰€æœ‰ï¼Œä½†æ˜¯æ³•å¾‹è§„å®šå±äºé›†ä½“æ‰€æœ‰...\n\n\n4\n7.03\n254\näº”ç«  å›½å®¶æ‰€æœ‰æƒå’Œé›†ä½“æ‰€æœ‰æƒã€ç§äººæ‰€æœ‰æƒ\nç¬¬äºŒç™¾äº”åå››æ¡ å›½é˜²èµ„äº§å±äºå›½å®¶æ‰€æœ‰ã€‚ é“è·¯ã€å…¬è·¯ã€ç”µåŠ›è®¾æ–½ã€ç”µä¿¡è®¾æ–½å’Œæ²¹æ°”ç®¡é“ç­‰åŸºç¡€è®¾æ–½ï¼Œ...\n\n\n\n\n\n\n\n\n\nDense semantic retrieval\nDense retrieval (BGE embedding-based FAISS search) captures semantic similarity and paraphrased intent.\n\n\n\n\n\n\n\n\n\nscore\narticle_id\nchapter\npreview\n\n\n\n\n0\n0.65\n495\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åäº”æ¡ å½“äº‹äººçº¦å®šåœ¨å°†æ¥ä¸€å®šæœŸé™å†…è®¢ç«‹åˆåŒçš„è®¤è´­ä¹¦ã€è®¢è´­ä¹¦ã€é¢„è®¢ä¹¦ç­‰ï¼Œæ„æˆé¢„çº¦åˆåŒã€‚...\n\n\n1\n0.53\n491\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸€æ¡ å½“äº‹äººé‡‡ç”¨ä¿¡ä»¶ã€æ•°æ®ç”µæ–‡ç­‰å½¢å¼è®¢ç«‹åˆåŒè¦æ±‚ç­¾è®¢ç¡®è®¤ä¹¦çš„ï¼Œç­¾è®¢ç¡®è®¤ä¹¦æ—¶åˆåŒæˆç«‹...\n\n\n2\n0.53\n471\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¸ƒåä¸€æ¡ å½“äº‹äººè®¢ç«‹åˆåŒï¼Œå¯ä»¥é‡‡å–è¦çº¦ã€æ‰¿è¯ºæ–¹å¼æˆ–è€…å…¶ä»–æ–¹å¼ã€‚...\n\n\n3\n0.51\n493\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸‰æ¡ å½“äº‹äººé‡‡ç”¨åˆåŒä¹¦å½¢å¼è®¢ç«‹åˆåŒçš„ï¼Œæœ€åç­¾åã€ç›–ç« æˆ–è€…æŒ‰æŒ‡å°çš„åœ°ç‚¹ä¸ºåˆåŒæˆç«‹çš„åœ°...\n\n\n4\n0.51\n483\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾å…«åä¸‰æ¡ æ‰¿è¯ºç”Ÿæ•ˆæ—¶åˆåŒæˆç«‹ï¼Œä½†æ˜¯æ³•å¾‹å¦æœ‰è§„å®šæˆ–è€…å½“äº‹äººå¦æœ‰çº¦å®šçš„é™¤å¤–ã€‚...\n\n\n\n\n\n\n\n\n\nLate-interaction retrieval\nLate-interaction retrieval (ColBERT) encodes each token into a contextualized embedding and computes relevance through fine-grained tokenâ€“token interactions at query time. This design preserves detailed lexical signals while retaining strong semantic generalization.\n\n\n\n\n\n\n\n\n\nscore\narticle_id\nchapter\npreview\n\n\n\n\n0\n22.08\n495\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åäº”æ¡ å½“äº‹äººçº¦å®šåœ¨å°†æ¥ä¸€å®šæœŸé™å†…è®¢ç«‹åˆåŒçš„è®¤è´­ä¹¦ã€è®¢è´­ä¹¦ã€é¢„è®¢ä¹¦ç­‰ï¼Œæ„æˆé¢„çº¦åˆåŒã€‚...\n\n\n1\n19.97\n502\nä¸‰ç«  åˆåŒçš„æ•ˆåŠ›\nç¬¬äº”ç™¾é›¶äºŒæ¡ ä¾æ³•æˆç«‹çš„åˆåŒï¼Œè‡ªæˆç«‹æ—¶ç”Ÿæ•ˆï¼Œä½†æ˜¯æ³•å¾‹å¦æœ‰è§„å®šæˆ–è€…å½“äº‹äººå¦æœ‰çº¦å®šçš„é™¤å¤–ã€‚ ä¾ç…§...\n\n\n2\n19.92\n493\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸‰æ¡ å½“äº‹äººé‡‡ç”¨åˆåŒä¹¦å½¢å¼è®¢ç«‹åˆåŒçš„ï¼Œæœ€åç­¾åã€ç›–ç« æˆ–è€…æŒ‰æŒ‡å°çš„åœ°ç‚¹ä¸ºåˆåŒæˆç«‹çš„åœ°...\n\n\n3\n19.88\n888\näºŒåä¸€ç«  ä¿ç®¡åˆåŒ\nç¬¬å…«ç™¾å…«åå…«æ¡ ä¿ç®¡åˆåŒæ˜¯ä¿ç®¡äººä¿ç®¡å¯„å­˜äººäº¤ä»˜çš„ä¿ç®¡ç‰©ï¼Œå¹¶è¿”è¿˜è¯¥ç‰©çš„åˆåŒã€‚ å¯„å­˜äººåˆ°ä¿ç®¡äººå¤„...\n\n\n4\n19.84\n984\näºŒåä¹ç«  ä¸å½“å¾—åˆ©\nç¬¬ä¹ç™¾å…«åå››æ¡ ç®¡ç†äººç®¡ç†äº‹åŠ¡ç»å—ç›Šäººäº‹åè¿½è®¤çš„ï¼Œä»ç®¡ç†äº‹åŠ¡å¼€å§‹æ—¶èµ·ï¼Œé€‚ç”¨å§”æ‰˜åˆåŒçš„æœ‰å…³è§„å®š...\n\n\n\n\n\n\n\n\n\nMulti-channel Retrieval Fusion\nTo integrate heterogeneous retrieval signals, Legal-RAG applies a fusion step over the multi-channel results. Two fusion strategies are supported:\n\nReciprocal Rank Fusion (RRF) Candidates are ranked based on the inverse of their rank positions across channels, emphasizing consensus among retrievers.\nNormalized score blending (norm_blend) Raw scores from different retrievers are normalized into a comparable range and linearly combined.\n\nThis fusion step yields a unified ranked list of top candidates, mitigating the weaknesses of any single retrieval method.\n\n\n\n\n\n\n\n\n\nscore\narticle_id\nchapter\npreview\nchannel\n\n\n\n\n0\n1.18\n495\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åäº”æ¡ å½“äº‹äººçº¦å®šåœ¨å°†æ¥ä¸€å®šæœŸé™å†…è®¢ç«‹åˆåŒçš„è®¤è´­ä¹¦ã€è®¢è´­ä¹¦ã€é¢„è®¢ä¹¦ç­‰ï¼Œæ„æˆé¢„çº¦åˆåŒã€‚...\n[dense, bm25, colbert]\n\n\n1\n0.32\n491\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸€æ¡ å½“äº‹äººé‡‡ç”¨ä¿¡ä»¶ã€æ•°æ®ç”µæ–‡ç­‰å½¢å¼è®¢ç«‹åˆåŒè¦æ±‚ç­¾è®¢ç¡®è®¤ä¹¦çš„ï¼Œç­¾è®¢ç¡®è®¤ä¹¦æ—¶åˆåŒæˆç«‹...\n[dense, colbert]\n\n\n2\n0.31\n471\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¸ƒåä¸€æ¡ å½“äº‹äººè®¢ç«‹åˆåŒï¼Œå¯ä»¥é‡‡å–è¦çº¦ã€æ‰¿è¯ºæ–¹å¼æˆ–è€…å…¶ä»–æ–¹å¼ã€‚...\n[dense, colbert]\n\n\n3\n0.30\n493\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸‰æ¡ å½“äº‹äººé‡‡ç”¨åˆåŒä¹¦å½¢å¼è®¢ç«‹åˆåŒçš„ï¼Œæœ€åç­¾åã€ç›–ç« æˆ–è€…æŒ‰æŒ‡å°çš„åœ°ç‚¹ä¸ºåˆåŒæˆç«‹çš„åœ°...\n[dense, colbert]\n\n\n4\n0.22\n469\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾å…­åä¹æ¡ å½“äº‹äººè®¢ç«‹åˆåŒï¼Œå¯ä»¥é‡‡ç”¨ä¹¦é¢å½¢å¼ã€å£å¤´å½¢å¼æˆ–è€…å…¶ä»–å½¢å¼ã€‚ ä¹¦é¢å½¢å¼æ˜¯åˆåŒä¹¦ã€...\n[colbert, dense]\n\n\n\n\n\n\n\n\n\nGraph-Augmented Retrieval\nTo capture structural legal relationships, such as:\n\nGeneralâ€“specific rule hierarchies\nCross-article references\nImplicit doctrinal dependencies\n\na graph-based enhancement stage is applied. Using the fusion top candidates as seeds, a graph walk augments the candidate set with structurally relevant but textually under-retrieved articles.\n\n\n\n\n\n\n\n\n\nscore\narticle_id\nchapter\npreview\n\n\n\n\n0\n0.36\n490\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åæ¡ å½“äº‹äººé‡‡ç”¨åˆåŒä¹¦å½¢å¼è®¢ç«‹åˆåŒçš„ï¼Œè‡ªå½“äº‹äººå‡ç­¾åã€ç›–ç« æˆ–è€…æŒ‰æŒ‡å°æ—¶åˆåŒæˆç«‹ã€‚åœ¨ç­¾...\n\n\n1\n0.34\n494\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åå››æ¡ å›½å®¶æ ¹æ®æŠ¢é™©æ•‘ç¾ã€ç–«æƒ…é˜²æ§æˆ–è€…å…¶ä»–éœ€è¦ä¸‹è¾¾å›½å®¶è®¢è´§ä»»åŠ¡ã€æŒ‡ä»¤æ€§ä»»åŠ¡çš„ï¼Œæœ‰å…³æ°‘...\n\n\n2\n0.34\n472\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¸ƒåäºŒæ¡ è¦çº¦æ˜¯å¸Œæœ›ä¸ä»–äººè®¢ç«‹åˆåŒçš„æ„æ€è¡¨ç¤ºï¼Œè¯¥æ„æ€è¡¨ç¤ºåº”å½“ç¬¦åˆä¸‹åˆ—æ¡ä»¶ï¼š ï¼ˆä¸€ï¼‰å†…å®¹...\n\n\n3\n0.34\n470\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¸ƒåæ¡ åˆåŒçš„å†…å®¹ç”±å½“äº‹äººçº¦å®šï¼Œä¸€èˆ¬åŒ…æ‹¬ä¸‹åˆ—æ¡æ¬¾ï¼š ï¼ˆä¸€ï¼‰å½“äº‹äººçš„å§“åæˆ–è€…åç§°å’Œä½æ‰€ï¼›...\n\n\n4\n0.33\n492\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åäºŒæ¡ æ‰¿è¯ºç”Ÿæ•ˆçš„åœ°ç‚¹ä¸ºåˆåŒæˆç«‹çš„åœ°ç‚¹ã€‚ é‡‡ç”¨æ•°æ®ç”µæ–‡å½¢å¼è®¢ç«‹åˆåŒçš„ï¼Œæ”¶ä»¶äººçš„ä¸»è¥ä¸š...\n\n\n\n\n\n\n\n\n\nReranking\nA reranking stage using cross-encoder or LLM-based scoring refines ordering at the end. Reranking prioritizes answer-critical provisions while demoting peripheral or weakly connected articles based on higher-resolution signals, such as:\n\nQueryâ€“article semantic alignment\nCoverage of legally salient terms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nscore\narticle_id\nchapter\npreview\nchannel\n\n\n\n\n0\n1.11\n495\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åäº”æ¡ å½“äº‹äººçº¦å®šåœ¨å°†æ¥ä¸€å®šæœŸé™å†…è®¢ç«‹åˆåŒçš„è®¤è´­ä¹¦ã€è®¢è´­ä¹¦ã€é¢„è®¢ä¹¦ç­‰ï¼Œæ„æˆé¢„çº¦åˆåŒã€‚...\n[dense, bm25, colbert]\n\n\n1\n0.21\n491\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸€æ¡ å½“äº‹äººé‡‡ç”¨ä¿¡ä»¶ã€æ•°æ®ç”µæ–‡ç­‰å½¢å¼è®¢ç«‹åˆåŒè¦æ±‚ç­¾è®¢ç¡®è®¤ä¹¦çš„ï¼Œç­¾è®¢ç¡®è®¤ä¹¦æ—¶åˆåŒæˆç«‹...\n[dense, colbert]\n\n\n2\n0.20\n471\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¸ƒåä¸€æ¡ å½“äº‹äººè®¢ç«‹åˆåŒï¼Œå¯ä»¥é‡‡å–è¦çº¦ã€æ‰¿è¯ºæ–¹å¼æˆ–è€…å…¶ä»–æ–¹å¼ã€‚...\n[dense, colbert]\n\n\n3\n0.19\n493\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾ä¹åä¸‰æ¡ å½“äº‹äººé‡‡ç”¨åˆåŒä¹¦å½¢å¼è®¢ç«‹åˆåŒçš„ï¼Œæœ€åç­¾åã€ç›–ç« æˆ–è€…æŒ‰æŒ‡å°çš„åœ°ç‚¹ä¸ºåˆåŒæˆç«‹çš„åœ°...\n[dense, colbert]\n\n\n4\n0.15\n469\näºŒç«  åˆåŒçš„è®¢ç«‹\nç¬¬å››ç™¾å…­åä¹æ¡ å½“äº‹äººè®¢ç«‹åˆåŒï¼Œå¯ä»¥é‡‡ç”¨ä¹¦é¢å½¢å¼ã€å£å¤´å½¢å¼æˆ–è€…å…¶ä»–å½¢å¼ã€‚ ä¹¦é¢å½¢å¼æ˜¯åˆåŒä¹¦ã€...\n[colbert, dense]"
  },
  {
    "objectID": "notebooks/03_Retrieval_Performance_Evaluation.html#evaluating-retrieval-pipelines-with-synthetic-questions",
    "href": "notebooks/03_Retrieval_Performance_Evaluation.html#evaluating-retrieval-pipelines-with-synthetic-questions",
    "title": "Retrieval Performance Evaluation",
    "section": "3 Evaluating Retrieval Pipelines with Synthetic Questions",
    "text": "3 Evaluating Retrieval Pipelines with Synthetic Questions\nThe generated synthetic dataset is used for systematic evaluation of retrieval performance in each stage:\n\nMulti-Channel Retrieval, combining dense semantic search, sparse lexical matching, and late-interaction models.\nGraph-Augmented Retrieval, with legal graph expansion.\nReranking, final ranking by applying a cross-encoder or LLM.\n\n\n\nDefine Retrieval Evaluation Metrics\nfrom collections import defaultdict\nfrom typing import Callable\nimport math\n\n\ndef _hit_ids(hits: List[RetrievalHit]) -&gt; List[str]:\n    # compare at article_id level for legal retrieval\n    out = []\n    for h in hits:\n        aid = str(getattr(h.chunk, \"article_id\", \"\") or \"\")\n        if aid:\n            out.append(aid)\n    return out\n\ndef hit_at_k(pred: List[str], gold: Set[str], k: int) -&gt; float:\n    top_hits = pred[:k]\n    return int(any(h.strip() in gold for h in top_hits))\n\ndef recall_at_k(pred: List[str], gold: Set[str], k: int) -&gt; float:\n    if not gold:\n        return 0.0\n    return len(set(pred[:k]) & gold) / len(gold)\n\ndef mrr_at_k(pred: List[str], gold: Set[str], k: int) -&gt; float:\n    for i, x in enumerate(pred[:k], start=1):\n        if x in gold:\n            return 1.0 / i\n    return 0.0\n\ndef ndcg_at_k(pred: List[str], gold: Set[str], k: int) -&gt; float:\n    # binary relevance\n    def dcg(xs: List[str]) -&gt; float:\n        s = 0.0\n        for i, x in enumerate(xs[:k], start=1):\n            rel = 1.0 if x in gold else 0.0\n            s += rel / math.log2(i + 1)\n        return s\n    ideal = dcg(list(gold))\n    if ideal &lt;= 1e-12:\n        return 0.0\n    return dcg(pred) / ideal\n\n\n\n\nEvaluate on the Systematic Dataset\nsubset = df_queries.sample(100, random_state=0).reset_index(drop=True)\n\nresults = []\nfor _, row in subset.iterrows():\n    out = evaluate_one(row[\"query\"], [row[\"article_id\"]], top_k=10)\n    results.append({\n        \"query\": row[\"query\"],\n        \"positives\": row[\"article_id\"],\n        \"hits\":  out[\"hits\"],\n        \"metrics\": out[\"metrics\"],\n    })\n\n\n\n\n\n\n\n  \n    \n      \n      R@5\n      R@10\n      MRR@10\n      nDCG@10\n      hit@3\n      hit@10\n        \n  \n    \n      fusion\n      0.82\n      0.85\n      0.650857\n      0.699083\n      0.70\n      0.85\n    \n    \n      hybrid\n      0.82\n      0.84\n      0.690524\n      0.727520\n      0.75\n      0.84\n    \n    \n      colbert\n      0.79\n      0.81\n      0.663024\n      0.699208\n      0.71\n      0.81\n    \n    \n      dense\n      0.66\n      0.75\n      0.528690\n      0.582100\n      0.60\n      0.75\n    \n    \n      bm25\n      0.52\n      0.57\n      0.443345\n      0.473788\n      0.49\n      0.57"
  },
  {
    "objectID": "notebooks/03_Retrieval_Performance_Evaluation.html#key-observations",
    "href": "notebooks/03_Retrieval_Performance_Evaluation.html#key-observations",
    "title": "Retrieval Performance Evaluation",
    "section": "4 Key observations",
    "text": "4 Key observations\n\nNeural retrieval consistently outperforms lexical BM25. Both dense and ColBERT retrievers achieve substantial gains over BM25 across all metrics (e.g., R@10, MRR@10, nDCG@10), indicating that semantic matching is essential for legal queries with abstract or paraphrased formulations.\nLate-interaction retrieval (ColBERT) further improves ranking quality. Compared to standard dense retrieval, ColBERT yields higher nDCG@10 and hit@k scores, suggesting better fine-grained alignment between queries and statutory text.\nMulti-retriever fusion provides robust and consistent improvements. The fusion variant, which combines BM25, dense, and ColBERT retrieval results, achieves the strongest overall recall and ranking performance, benefiting from complementary retrieval signals.\nHybrid retrieval with augmentation and reranking achieves the best performance. The hybrid retrieverâ€”built on top of fusion and further enhanced with optional graph-based augmentation and rerankingâ€”consistently attains the highest scores across nearly all metrics. In particular, it shows clear gains over pure BM25 and pure dense retrieval, confirming the effectiveness of combining heterogeneous retrievers with structural and ranking enhancements.\n\nOverall, the results demonstrate that progressively enriched retrieval pipelinesâ€”from lexical to semantic, from single retriever to fused and augmented retrieversâ€”lead to systematic and measurable improvements in legal retrieval quality."
  },
  {
    "objectID": "docs/demo.html",
    "href": "docs/demo.html",
    "title": "",
    "section": "",
    "text": "Code"
  },
  {
    "objectID": "index.html#what-is-legal-rag",
    "href": "index.html#what-is-legal-rag",
    "title": "Legal-RAG",
    "section": "1 What is Legal-RAG?",
    "text": "1 What is Legal-RAG?\nLegal-RAG is an open-source, end-to-end legal Retrieval-Augmented Generation (RAG) system centered on statutory text. It integrates hybrid retrieval, QueryType-aware routing, bounded graph-augmented context expansion, and provider-agnostic token streaming."
  },
  {
    "objectID": "index.html#hugging-face-spaces-demo-online",
    "href": "index.html#hugging-face-spaces-demo-online",
    "title": "Legal-RAG",
    "section": "2 ğŸ¤— Hugging Face Spaces Demo (Online)",
    "text": "2 ğŸ¤— Hugging Face Spaces Demo (Online)\nğŸ‘‰ https://huggingface.co/spaces/flora-l/Legal-RAG\nNote: This Space does not currently have GPU resources enabled, so local Qwen models are unavailable. Please use an OpenAI model for answer generation with your OPENAI_API_KEY."
  },
  {
    "objectID": "index.html#features",
    "href": "index.html#features",
    "title": "Legal-RAG",
    "section": "3 Features",
    "text": "3 Features\n\nLaw-aware RAG\n\nExplicit article-level chunking\nLaw-specific metadata (chapter / section / article number)\nRetrieval results are inspectable and auditable\nLanguage-aware corpus routing (zh/en)\n\n\n\nHybrid Retrieval\n\nDense retrieval: FAISS\nSparse retrieval: BM25\nColBERT (late interaction)\nWeighted fusion\n\n\n\nQuery Routing & Graph Awareness\n\nLightweight law_graph for structural reasoning\nRouter decides between:\n\npure retrieval\ngraph-assisted RAG\n\nClear extension point for richer legal knowledge graphs\n\n\n\nOnline PDF Ingestion (Incremental Indexing)\n\nUpload PDFs â†’ parse â†’ chunk â†’ JSONL\nIncremental FAISS add\nBM25 rebuild in background"
  },
  {
    "objectID": "index.html#system-architecture",
    "href": "index.html#system-architecture",
    "title": "Legal-RAG",
    "section": "4 System Architecture",
    "text": "4 System Architecture\nThe system is organized into four clearly separated layers:\n\nOffline Build Law text preprocessing, index construction, graph building\nIndex Artifacts FAISS, BM25, and law_graph as immutable read models\nOnline Ingestion PDF upload â†’ background incremental indexing\nOnline Serving (RAG + Routing) FastAPI + RagPipeline + Router + LLM\n\nSee the architecture diagram for the full data flow."
  },
  {
    "objectID": "index.html#quickstart-local",
    "href": "index.html#quickstart-local",
    "title": "Legal-RAG",
    "section": "5 Quickstart (Local)",
    "text": "5 Quickstart (Local)\n\n1. Clone & install\ngit clone https://github.com/Fan-Luo/Legal-RAG.git\ncd Legal-RAG\npip install -r requirements.txt\n\n\n2. Prepare law data & build index\nThe default corpus includes:\n\nChinese: PRC Civil Code\nEnglish: Uniform Commercial Code (UCC)\n\nQueries are routed to language-specific corpora and indexes.\n# preprocess law text into structured JSONL\npython -m scripts.preprocess_law\n\n# build FAISS + BM25 indexes\npython -m scripts.build_index\n\n# build law_graph\npython -m scripts.build_graph\nArtifacts are generated per language:\n\ndata/processed/law_zh.jsonl, data/processed/law_en.jsonl\ndata/index/zh/..., data/index/en/...\ndata/graph/law_graph_zh.jsonl, data/graph/law_graph_en.jsonl\n\n\n\n3. Start API service\npython -m uvicorn legalrag.api.server:app --host 127.0.0.1 --port 8000 \n\n\n4. Launch Demo\nvisit http://127.0.0.1:8000/ or http://127.0.0.1:8000/ui/"
  },
  {
    "objectID": "index.html#example",
    "href": "index.html#example",
    "title": "Legal-RAG",
    "section": "6 Example",
    "text": "6 Example\nfrom legalrag.config import AppConfig\nfrom legalrag.pipeline.rag_pipeline import RagPipeline\n\ncfg = AppConfig.load()\npipeline = RagPipeline(cfg)\n\nquestion = \"What standards must goods satisfy to be merchantableï¼Ÿ\"\nans = pipeline.answer(question)\n\nprint(ans.answer)"
  },
  {
    "objectID": "index.html#llm-backends-cost-model",
    "href": "index.html#llm-backends-cost-model",
    "title": "Legal-RAG",
    "section": "7 LLM Backends & Cost Model",
    "text": "7 LLM Backends & Cost Model\nSupported backends:\n\nLocal LLM (Qwen series, need GPU and enough memory)\nOpenAI-compatible API (need to provide OpenAI API key)\n\nNo API key is collected via UI\nLLM keys are read only from environment variables Note: If no key is provided and no local model loaded, the system gracefully degrades"
  },
  {
    "objectID": "index.html#project-structure",
    "href": "index.html#project-structure",
    "title": "Legal-RAG",
    "section": "8 Project Structure",
    "text": "8 Project Structure\nLegal-RAG/\nâ”‚\nâ”œâ”€â”€ legalrag/\nâ”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”œâ”€â”€ config.py                   \nâ”‚   â”œâ”€â”€ schemas.py                 # LawChunk / RetrievalHit / RoutingDecision / RagAnswer\nâ”‚   â”œâ”€â”€ llm/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ gateway.py\nâ”‚   â”‚   â””â”€â”€ client.py              # Qwen / OpenAI LLMClient \nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ routing/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ legal_issue_extractor.py\nâ”‚   â”‚   â””â”€â”€ router.py              # QueryType + Graph/RAG Suggestions\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ retrieval/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ builders\nâ”‚   â”‚   â”œâ”€â”€ dense_retriever.py     # Dense (BGE + FAISS)\nâ”‚   â”‚   â”œâ”€â”€ vector_store.py        \nâ”‚   â”‚   â”œâ”€â”€ bm25_retriever.py      # Sparse (BM25 + jieba)\nâ”‚   â”‚   â”œâ”€â”€ colbert_retriever.py\nâ”‚   â”‚   â”œâ”€â”€ hybrid_retriever.py    # Dense + Sparse + Colbert + Graph + Rerank\nâ”‚   â”‚   â”œâ”€â”€ by_lang_retriever.py   # zh/en routing\nâ”‚   â”‚   â”œâ”€â”€ corpus_loader.py       # read all chunks from processed_dir\nâ”‚   â”‚   â”œâ”€â”€ incremental_indexer.py\nâ”‚   â”‚   â”œâ”€â”€ graph_retriever.py\nâ”‚   â”‚   â”œâ”€â”€ graph_store.py         # law_graph / legal_kg  \nâ”‚   â”‚   â””â”€â”€ rerankers.py\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ pdf/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ parser.py              # pdfplumber + OCR fallback\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ ingest/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ orchestrator.py\nâ”‚   â”‚   â”œâ”€â”€ service.py\nâ”‚   â”‚   â”œâ”€â”€ task_queue.py\nâ”‚   â”‚   â””â”€â”€ ingestor.py            # PDFIngestor \nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ pipeline/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â””â”€â”€ rag_pipeline.py        # Graph-aware RAG Core Inference\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ prompts/\nâ”‚   â”‚   â”œâ”€â”€ prompt_zh.json         # Chinese prompt\nâ”‚   â”‚   â””â”€â”€ prompt_en.json         # English prompt\nâ”‚   â”‚\nâ”‚   â”œâ”€â”€ utils/\nâ”‚   â”‚   â”œâ”€â”€ __init__.py\nâ”‚   â”‚   â”œâ”€â”€ lang.py\nâ”‚   â”‚   â”œâ”€â”€ logger.py             \nâ”‚   â”‚   â””â”€â”€ text.py                \nâ”‚   â”‚\nâ”‚   â””â”€â”€ api/\nâ”‚       â”œâ”€â”€ __init__.py\nâ”‚       â””â”€â”€ server.py              # FastAPIï¼ˆ/rag/retrieve, /rag/answer, /ingest/pdfï¼‰\nâ”‚\nâ”œâ”€â”€ ui/\nâ”‚   â”œâ”€â”€ index.html\nâ”‚   â””â”€â”€ demo.qmd\nâ”‚\nâ”œâ”€â”€ scripts/\nâ”‚   â”œâ”€â”€ preprocess_law.py          # parse law â†’ LawChunk JSONL\nâ”‚   â”œâ”€â”€ build_index.py             # FAISS + BM25 + Colbert indexes\nâ”‚   â”œâ”€â”€ build_graph.py             # law_graph / legal_kg  \nâ”‚   â”œâ”€â”€ bgenerate_synthetic_data.py\nâ”‚   â””â”€â”€ evaluate_retrieval.py      # Hit@K / MRR / nDCG\nâ”‚\nâ”œâ”€â”€ notebooks/\nâ”‚   â”œâ”€â”€ 01_Launch_the_UI.ipynb\nâ”‚   â”œâ”€â”€ 02_LegalRAG_Pipeline.ipynb\nâ”‚   â”œâ”€â”€ 03_Retrieval_Performance_Evaluation.ipynb\nâ”‚   â””â”€â”€ 04_Law_Graph_Visualization.ipynb\nâ”‚\nâ”œâ”€â”€ data/\nâ”‚   â”œâ”€â”€ raw/                         \nâ”‚   â”‚   â”œâ”€â”€ minfadian.txt            \nâ”‚   â”‚   â””â”€â”€ ucc/                    \nâ”‚   â”œâ”€â”€ processed/                 # law_zh.jsonl / law_en.jsonl\nâ”‚   â”œâ”€â”€ index/                     # faiss/bm25/colbert per language\nâ”‚   â””â”€â”€ graph/                     # law_graph_zh.jsonl / law_graph_en.jsonl\nâ”‚   â””â”€â”€ eval/\nâ”‚       \nâ”œâ”€â”€ docs/\nâ”‚   â”œâ”€â”€ architecture.mmd\nâ”‚   â””â”€â”€ architecture.png\nâ”‚ \nâ”œâ”€â”€ tests/\nâ”‚   â”œâ”€â”€ test_router.py\nâ”‚   â””â”€â”€ test_retrieval.py\nâ”‚ \nâ”œâ”€â”€ README.md\nâ”œâ”€â”€ README-zh.md\nâ”œâ”€â”€ LICENSE\nâ”œâ”€â”€ pyproject.toml\nâ”œâ”€â”€ requirements.txt\nâ”œâ”€â”€ _quarto.yml\nâ”œâ”€â”€ index..qmd\nâ”œâ”€â”€ app.py                           # Hugging Face Space entry\nâ”œâ”€â”€ Dockerfile\nâ””â”€â”€ .gitignore"
  },
  {
    "objectID": "index.html#who-is-this-project-for",
    "href": "index.html#who-is-this-project-for",
    "title": "Legal-RAG",
    "section": "9 Who is this project for?",
    "text": "9 Who is this project for?\nThis repository is intended for:\n\nEngineers exploring RAG system design\nResearchers working on legal NLP / AI + law\nPractitioners interested in traceable AI systems\nCandidates demonstrating architecture-level thinking\n\n\nâš ï¸ This project provides legal information assistance for educational and research purposes only and does not constitute legal advice. Users should not rely on this project as a substitute for professional legal counsel. The authors and contributors disclaim any liability for any direct or indirect consequences arising from the use of this project."
  },
  {
    "objectID": "index.html#extensibility",
    "href": "index.html#extensibility",
    "title": "Legal-RAG",
    "section": "10 Extensibility",
    "text": "10 Extensibility\nLegal-RAG is intentionally structured to support:\n\nricher legal knowledge graphs\nmulti-document reasoning\nmulti-tenant isolation\nBYOK (Bring Your Own Key) SaaS models\n\nThese are architectural affordances, not product promises."
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Legal-RAG",
    "section": "11 License",
    "text": "11 License\nApache License 2.0\nThis repository contains source code only. Users are responsible for complying with the licenses of any models or APIs they choose to integrate."
  },
  {
    "objectID": "notebooks/04_Law_Graph_Visualization.html",
    "href": "notebooks/04_Law_Graph_Visualization.html",
    "title": "Law Graph Visualization",
    "section": "",
    "text": "This notebook presents an interactive visualization of the legal knowledge graph.\nThe graph makes explicit the structural relationships between statutory provisions that are otherwise difficult to observe through text-only retrieval.\nThis visualization serves both as a diagnostic tool and as an explanatory aid for understanding how graph enhancement influences retrieval and downstream answer generation."
  },
  {
    "objectID": "notebooks/04_Law_Graph_Visualization.html#build-and-load-the-graph",
    "href": "notebooks/04_Law_Graph_Visualization.html#build-and-load-the-graph",
    "title": "Law Graph Visualization",
    "section": "1 Build and Load the Graph",
    "text": "1 Build and Load the Graph\nAfter pull the project source code, the preprocessing stage constructs a legal knowledge graph to capture structural relationships:\ngit clone https://github.com/Fan-Luo/Legal-RAG.git\npip install -e .\npython -m scripts.preprocess_law\npython -m scripts.build_graph"
  },
  {
    "objectID": "notebooks/04_Law_Graph_Visualization.html#what-this-graph-represents",
    "href": "notebooks/04_Law_Graph_Visualization.html#what-this-graph-represents",
    "title": "Law Graph Visualization",
    "section": "2 What This Graph Represents",
    "text": "2 What This Graph Represents\nNodes correspond to individual legal provisions (e.g., articles or clauses).\nEdges encode structural relationships, capturing referential and contextual dependencies among laws.\nThe graph is constructed offline from preprocessed legal texts and stored as a static HTML artifact for reproducible inspection.\n\nfrom legalrag.config import AppConfig\nfrom legalrag.retrieval.graph_store import LawGraphStore\n\ncfg = AppConfig.load(None)\nstore = LawGraphStore(cfg)\n\n\n\n[Graph] Loaded 1260 law nodes\n[Graph] Built adjacency: 2640 edges\n\n\n\n\nExample graph node:\n  Article ID   : 142\n  Article No   : ç¬¬ä¸€ç™¾å››åäºŒæ¡\n  Law          : ä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸\n  Chapter      : å…­ç«  æ°‘äº‹æ³•å¾‹è¡Œä¸º\n  Section      : ä¸‰èŠ‚ æ°‘äº‹æ³•å¾‹è¡Œä¸ºçš„æ•ˆåŠ›\n\n  Neighbors:\n    -  141 | rel=prev   | conf=1.00 | evidence=None\n    -  143 | rel=next   | conf=1.00 | evidence=None\n    -  466 | rel=cited  | conf=0.90 | evidence={'span': [30, 37], 'text': 'ç¬¬ä¸€ç™¾å››åäºŒæ¡'}"
  },
  {
    "objectID": "notebooks/04_Law_Graph_Visualization.html#graph-walk-retrieval",
    "href": "notebooks/04_Law_Graph_Visualization.html#graph-walk-retrieval",
    "title": "Law Graph Visualization",
    "section": "3 Graph Walk Retrieval",
    "text": "3 Graph Walk Retrieval\nGraph-based expansion performs a bounded breadth-first search (BFS) over the legal knowledge graph, starting from one or more seed articles. The goal is to retrieve a localized subgraph centered on the query nodes, while allowing fine-grained control over relation types, confidence thresholds, and the total number of returned nodes. The resulting nodes are used to induce a subgraph for visualization or downstream analysis.\n\nstart_ids = [\"582\"]\nlaw_nodes = store.walk(start_ids, limit = 30)\nnode_ids = [node.article_id for node in law_nodes] + start_ids"
  },
  {
    "objectID": "notebooks/04_Law_Graph_Visualization.html#visualizing-the-legal-knowledge-graph",
    "href": "notebooks/04_Law_Graph_Visualization.html#visualizing-the-legal-knowledge-graph",
    "title": "Law Graph Visualization",
    "section": "4 Visualizing the Legal Knowledge Graph",
    "text": "4 Visualizing the Legal Knowledge Graph\nThis section visualizes the full legal knowledge graph as an interactive network to facilitate inspection and analysis of structural relationships between legal articles. Nodes represent individual law articles, while directed edges encode relational links such as sequential ordering, citations, or doctrinal dependencies.\nThis visualization complements quantitative retrieval metrics by providing a qualitative view of legal structure and coverage."
  },
  {
    "objectID": "notebooks/01_Launch_the_UI.html",
    "href": "notebooks/01_Launch_the_UI.html",
    "title": "Launch the UI",
    "section": "",
    "text": "ğŸš€ Launch the server locally and explore the interactive UI to query legal provisions and get evidence-backed results instantly!"
  },
  {
    "objectID": "notebooks/01_Launch_the_UI.html#repository-clone-and-setup",
    "href": "notebooks/01_Launch_the_UI.html#repository-clone-and-setup",
    "title": "Launch the UI",
    "section": "1 Repository Clone and Setup",
    "text": "1 Repository Clone and Setup\nFirst, pull the project source code, initialize the execution environment, and run the data preprocessing.\n\n!git clone https://github.com/Fan-Luo/Legal-RAG.git\n%cd Legal-RAG\n!python -m scripts.setup"
  },
  {
    "objectID": "notebooks/01_Launch_the_UI.html#start-the-local-legalrag-api-server",
    "href": "notebooks/01_Launch_the_UI.html#start-the-local-legalrag-api-server",
    "title": "Launch the UI",
    "section": "2 Start the local LegalRAG API server",
    "text": "2 Start the local LegalRAG API server\n\nimport os, time, subprocess, requests\nfrom legalrag.config import AppConfig\ncfg = AppConfig.load(None)\nPORT = 7900\n\nenv = {\n    **os.environ,\n    \"PORT\": str(PORT),\n    cfg.llm.qwen_model_env: \"Qwen/Qwen2.5-3B-Instruct\",  \n}\n\nuv = subprocess.Popen(\n    [\"python\", \"-m\", \"uvicorn\", \"legalrag.api.server:app\",\n     \"--host\", \"0.0.0.0\", \"--port\", str(PORT), \"--log-level\", \"info\"],\n    env=env,\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    text=True,\n    bufsize=1\n)\n\nThe server listens on a local port and handles incoming requests for retrieval and answer legal generation."
  },
  {
    "objectID": "notebooks/01_Launch_the_UI.html#expose-the-service-via-a-public-tunnel",
    "href": "notebooks/01_Launch_the_UI.html#expose-the-service-via-a-public-tunnel",
    "title": "Launch the UI",
    "section": "3 Expose the Service via a Public Tunnel",
    "text": "3 Expose the Service via a Public Tunnel\nWith a Cloudflare Tunnel, the locally running LegalRAG service can be accessible via a public endpoint. The process involves launching the cloudflared subprocess to create a secure tunnel, capturing the temporary public URL generated by the tunnel, and ensuring the local service is fully initialized before it becomes publicly reachable.\n\n\nStarts a Cloudflare Tunnel for the local service\nproc = subprocess.Popen(\n    [\"./cloudflared\", \"tunnel\", \"--url\", f\"http://127.0.0.1:{PORT}\", \"--no-autoupdate\"],\n    stdout=subprocess.PIPE,\n    stderr=subprocess.STDOUT,\n    text=True,\n)\n\nthreading.Thread(\n    target=stream_logs,\n    args=(proc, logger),\n    daemon=True,\n).start()\n\nif not url_ready.wait(timeout=60):\n    raise RuntimeError(\"Failed to obtain Cloudflare Tunnel URL\")\n\n\n\n\nWaits for server warm-up before exposing the endpoint\nready = False\nfor _ in range(1000):\n    try:\n        r = requests.get(f\"http://127.0.0.1:{PORT}/ready\").json()\n        if r.get(\"warmup_done\"):\n            ready = True\n            break\n    except Exception:\n        pass\n    time.sleep(3)\n\nif not ready:\n    raise RuntimeError(\"Server not ready after warmup\")\n\nprint(\"Public URL:\", public_url)"
  },
  {
    "objectID": "notebooks/01_Launch_the_UI.html#interactive-ui-overview",
    "href": "notebooks/01_Launch_the_UI.html#interactive-ui-overview",
    "title": "Launch the UI",
    "section": "4 Interactive UI Overview",
    "text": "4 Interactive UI Overview\nThrough this UI, users can submit queries, visualize retrieved legal provisions, obtain evidence-grounded results, and upload additional reliable legal corpora."
  }
]