{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Legal-RAG 检索 Benchmark（合同法示例）\n",
        "\n",
        "本 Notebook 对比几种不同的检索配置在 **《民法典·合同编》** 场景下的效果：\n",
        "\n",
        "1. **BM25 only**：纯文本倒排检索（lexical）\n",
        "2. **Dense only**：BGE-base-zh-v1.5 + FAISS（纯语义向量）\n",
        "3. **Hybrid**：dense + BM25 加权融合\n",
        "4. **Graph-augmented**：在 Hybrid 基础上叠加 law_graph 扩展 + 语义 rerank \n",
        "\n",
        "指标：\n",
        "- Hit@1 / Hit@3 / Hit@5 / Hit@10\n",
        "\n",
        "> 说明：\n",
        "> - 本 Notebook 只评估“检索命中情况”，**不调用 LLM**。\n",
        "> - Ground truth 存在于 `data/eval/contract_law_qa.jsonl`，如果不存在，会自动写入一份简单示例。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 环境与路径检查\n",
        "\n",
        "需要提前运行：\n",
        "\n",
        "```bash\n",
        "python -m scripts.preprocess_law\n",
        "python -m scripts.build_index\n",
        "```\n",
        "\n",
        "已经构建好：\n",
        "- `data/processed/contract_law.jsonl`\n",
        "- `data/index/faiss.index` / `data/index/faiss_meta.jsonl`\n",
        "- `data/index/bm25.pkl`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "import json\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from legalrag.config import AppConfig\n",
        "from legalrag.models import RetrievalHit, QueryType, RoutingMode, LawChunk\n",
        "from legalrag.retrieval.bm25_retriever import BM25Retriever\n",
        "from legalrag.retrieval.vector_store import VectorStore\n",
        "from legalrag.retrieval.hybrid_retriever import HybridRetriever\n",
        "from legalrag.pipeline.rag_pipeline import RagPipeline\n",
        "from legalrag.routing.router import QueryRouter\n",
        "from legalrag.utils.logger import get_logger\n",
        "\n",
        "logger = get_logger(__name__)\n",
        "\n",
        "cfg = AppConfig.load()\n",
        "BASE_DIR = Path(cfg.paths.base_dir)\n",
        "DATA_DIR = Path(cfg.paths.data_dir)\n",
        "EVAL_DIR = Path(cfg.paths.eval_dir)\n",
        "EVAL_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"BASE_DIR:\", BASE_DIR)\n",
        "print(\"DATA_DIR:\", DATA_DIR)\n",
        "print(\"EVAL_DIR:\", EVAL_DIR)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 构造 / 加载 Ground Truth 数据集\n",
        "\n",
        "期望的 `contract_law_qa.jsonl` 结构示例：\n",
        "\n",
        "```json\n",
        "{\"question\": \"合同约定的违约金为合同金额的 40%，是否合理？\", \"target_articles\": [\"约定违约金的调整\", \"第 585 条\"]}\n",
        "{\"question\": \"什么是不可抗力？\", \"target_articles\": [\"不可抗力\", \"第 590 条\"]}\n",
        "```\n",
        "\n",
        "这里我们做一个简单约定：\n",
        "- `target_articles` 里既可以是条文编号（如 \"第585条\"），也可以是条文标题关键词（如 \"不可抗力\"）\n",
        "- 在匹配时会同时判断：\n",
        "  - 检索结果的 `article_no` 是否包含以上任意字符串\n",
        "  - 或者检索结果全文是否包含这些关键词"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "eval_path = EVAL_DIR / \"contract_law_qa.jsonl\"\n",
        "\n",
        "if not eval_path.exists():\n",
        "    print(\"[INFO] eval file not found, creating a small toy set at:\", eval_path)\n",
        "    toy_data = [\n",
        "        {\n",
        "            \"question\": \"合同约定的违约金为合同金额的 40%，是否合理？\",\n",
        "            \"target_articles\": [\"违约金\", \"过高\", \"调整\"]\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"什么是不可抗力？\",\n",
        "            \"target_articles\": [\"不可抗力\"]\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"合同一方迟延履行，另一方可以解除合同的条件是什么？\",\n",
        "            \"target_articles\": [\"解除合同\", \"迟延履行\"]\n",
        "        },\n",
        "        {\n",
        "            \"question\": \"当事人约定了定金，违约时如何处理定金？\",\n",
        "            \"target_articles\": [\"定金\", \"定金罚则\"]\n",
        "        }\n",
        "    ]\n",
        "    with eval_path.open(\"w\", encoding=\"utf-8\") as f:\n",
        "        for obj in toy_data:\n",
        "            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "\n",
        "def load_eval_data(path: Path) -> List[Dict[str, Any]]:\n",
        "    data = []\n",
        "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            data.append(json.loads(line))\n",
        "    return data\n",
        "\n",
        "\n",
        "eval_data = load_eval_data(eval_path)\n",
        "print(f\"Loaded {len(eval_data)} eval questions from {eval_path}\")\n",
        "eval_data[:2]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 初始化检索与 Graph-aware 组件\n",
        "\n",
        "这里我们初始化四种“检索模式”对应的对象：\n",
        "\n",
        "1. `BM25Retriever` – 纯文本检索\n",
        "2. `VectorStore` – dense（BGE + FAISS）\n",
        "3. `HybridRetriever` – dense + sparse\n",
        "4. `RagPipeline` – 其中的 `_graph_augmented_retrieval` 作为 Graph-aware 模式（不调用 LLM）\n",
        "\n",
        "> 注意：Graph 模式仍然依赖 Hybrid + law_graph + BGE encoder，属于在前三者基础上的扩展。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bm25 = BM25Retriever(cfg)\n",
        "vector_store = VectorStore(cfg)\n",
        "hybrid = HybridRetriever(cfg)\n",
        "pipeline = RagPipeline(cfg)\n",
        "router = QueryRouter(llm_client=pipeline.llm, llm_based=cfg.routing.llm_based)\n",
        "\n",
        "print(\"BM25, VectorStore, Hybrid, RagPipeline initialized.\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Hit@K 评估函数\n",
        "\n",
        "对于每个问题，我们会计算：\n",
        "\n",
        "- top-k 检索结果中是否出现“正确条文”（命中计为 1，未命中计为 0）\n",
        "- 对所有问题取平均，得到 Hit@K\n",
        "\n",
        "评估逻辑：\n",
        "- `target_articles` 是一组字符串，可匹配：\n",
        "  - `hit.chunk.article_no` 字段\n",
        "  - 或 `hit.chunk.text` 中是否包含这些关键词\n",
        "\n",
        "这样既兼容“目标是条号”，也兼容“目标是若干关键词／条文标签”。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from collections import defaultdict\n",
        "from typing import Callable\n",
        "\n",
        "def is_hit(chunk: LawChunk, targets: List[str]) -> bool:\n",
        "    if not targets:\n",
        "        return False\n",
        "    text = (chunk.text or \"\")\n",
        "    article_no = (getattr(chunk, \"article_no\", \"\") or \"\")\n",
        "    for t in targets:\n",
        "        t = t.strip()\n",
        "        if not t:\n",
        "            continue\n",
        "        if t in article_no:\n",
        "            return True\n",
        "        if t in text:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def eval_retriever(\n",
        "    name: str,\n",
        "    retrieve_fn: Callable[[str, int], List[RetrievalHit]],\n",
        "    eval_data: List[Dict[str, Any]],\n",
        "    ks: List[int] = [1, 3, 5, 10],\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"通用 Hit@K 评估函数。\n",
        "\n",
        "    retrieve_fn: (question, top_k) -> List[RetrievalHit]\n",
        "    \"\"\"\n",
        "    stats = {f\"hit@{k}\": 0.0 for k in ks}\n",
        "    n = 0\n",
        "\n",
        "    for item in eval_data:\n",
        "        q = item.get(\"question\", \"\")\n",
        "        targets = item.get(\"target_articles\", [])\n",
        "        if not q:\n",
        "            continue\n",
        "\n",
        "        max_k = max(ks)\n",
        "        try:\n",
        "            hits = retrieve_fn(q, max_k)\n",
        "        except Exception as e:\n",
        "            logger.error(f\"[{name}] failed on question: {q}; error={e}\")\n",
        "            continue\n",
        "\n",
        "        n += 1\n",
        "        for k in ks:\n",
        "            top_hits = hits[:k]\n",
        "            if any(is_hit(h.chunk, targets) for h in top_hits):\n",
        "                stats[f\"hit@{k}\"] += 1.0\n",
        "\n",
        "    if n == 0:\n",
        "        return {f\"hit@{k}\": 0.0 for k in ks}\n",
        "\n",
        "    for k in ks:\n",
        "        stats[f\"hit@{k}\"] /= n\n",
        "\n",
        "    print(f\"[{name}] evaluated on {n} questions:\")\n",
        "    for k in ks:\n",
        "        print(f\"  Hit@{k}: {stats[f'hit@{k}']:.3f}\")\n",
        "\n",
        "    return stats"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 定义各检索模式的接口\n",
        "\n",
        "我们分别为四种模式定义 `retrieve_fn`：\n",
        "\n",
        "1. `bm25_only` – 直接用 `BM25Retriever`\n",
        "2. `dense_only` – 直接用 `VectorStore`（FAISS+BGE）\n",
        "3. `hybrid_default` – `HybridRetriever`\n",
        "4. `graph_augmented` – 用 `RagPipeline` 的 graph 模式进行命中扩展 + 语义 rerank\n",
        "\n",
        "> 注意：graph 模式我们不调用 LLM，只用 `pipeline._graph_augmented_retrieval` 返回的 `RetrievalHit` 列表进行评估。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def retrieve_bm25(question: str, top_k: int) -> List[RetrievalHit]:\n",
        "    hits = []\n",
        "    for idx, (chunk, score) in enumerate(bm25.search(question, top_k=top_k), start=1):\n",
        "        hits.append(\n",
        "            RetrievalHit(\n",
        "                chunk=chunk,\n",
        "                score=float(score),\n",
        "                rank=idx,\n",
        "                source=\"bm25\",\n",
        "            )\n",
        "        )\n",
        "    return hits\n",
        "\n",
        "\n",
        "def retrieve_dense(question: str, top_k: int) -> List[RetrievalHit]:\n",
        "    hits = []\n",
        "    for idx, (chunk, score) in enumerate(vector_store.search(question, top_k), start=1):\n",
        "        hits.append(\n",
        "            RetrievalHit(\n",
        "                chunk=chunk,\n",
        "                score=float(score),\n",
        "                rank=idx,\n",
        "                source=\"dense\",\n",
        "            )\n",
        "        )\n",
        "    return hits\n",
        "\n",
        "\n",
        "def retrieve_hybrid(question: str, top_k: int) -> List[RetrievalHit]:\n",
        "    hits = hybrid.search(question, top_k=top_k)\n",
        "    for h in hits:\n",
        "        h.source = \"hybrid\"\n",
        "    return hits\n",
        "\n",
        "\n",
        "def retrieve_graph_augmented(question: str, top_k: int) -> List[RetrievalHit]:\n",
        "    # 使用 Router 推断 query_type，并指定 GRAPH_AUGMENTED 模式\n",
        "    decision = router.route(question)\n",
        "    decision.mode = RoutingMode.GRAPH_AUGMENTED\n",
        "\n",
        "    eff_top_k = max(3, min(int(top_k * getattr(decision, \"top_k_factor\", 1.0)), 30))\n",
        "\n",
        "    hits = pipeline._graph_augmented_retrieval(\n",
        "        question=question,\n",
        "        decision=decision,\n",
        "        top_k=eff_top_k,\n",
        "    )\n",
        "    # 为了公平比较，这里返回前 top_k 条\n",
        "    return hits[:top_k]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 运行评估并汇总结果\n",
        "\n",
        "我们在相同的 eval 集上计算四种模式的 Hit@K，并汇总成表格。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ks = [1, 3, 5, 10]\n",
        "\n",
        "results = {}\n",
        "results[\"bm25\"] = eval_retriever(\"BM25\", retrieve_bm25, eval_data, ks=ks)\n",
        "results[\"dense\"] = eval_retriever(\"Dense-BGE\", retrieve_dense, eval_data, ks=ks)\n",
        "results[\"hybrid\"] = eval_retriever(\"Hybrid\", retrieve_hybrid, eval_data, ks=ks)\n",
        "results[\"graph\"] = eval_retriever(\"Graph-augmented\", retrieve_graph_augmented, eval_data, ks=ks)\n",
        "\n",
        "df_rows = []\n",
        "for name, stats in results.items():\n",
        "    row = {\"retriever\": name}\n",
        "    row.update(stats)\n",
        "    df_rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(df_rows)\n",
        "df"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 可视化：不同检索模式的 Hit@K\n",
        "\n",
        "简单画一个并排柱状图，对比不同模式在各个 K 上的命中率。\n",
        "\n",
        "> 注意：为了遵循通用绘图习惯，这里使用 matplotlib 默认配色，不强制指定颜色。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def plot_hitk(df: pd.DataFrame, ks: List[int]):\n",
        "    metrics = [f\"hit@{k}\" for k in ks]\n",
        "    x = np.arange(len(metrics))  # [0, 1, 2, 3]\n",
        "\n",
        "    width = 0.18\n",        
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "\n",
        "    retrievers = list(df[\"retriever\"])\n",
        "    for i, name in enumerate(retrievers):\n",
        "        values = [df.loc[df[\"retriever\"] == name, m].values[0] for m in metrics]\n",
        "        ax.bar(x + i * width, values, width=width, label=name)\n",
        "\n",
        "    ax.set_xticks(x + width * (len(retrievers) - 1) / 2)\n",
        "    ax.set_xticklabels(metrics)\n",
        "    ax.set_ylim(0, 1.0)\n",
        "    ax.set_ylabel(\"Hit@K\")\n",
        "    ax.set_title(\"Legal-RAG Retrieval Benchmark (Contract Law QA)\")\n",
        "    ax.legend()\n",
        "    ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_hitk(df, ks=ks)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 小结\n",
        "\n",
        "- 在自构造的合同法 QA 集上，对比了 BM25 / Dense-BGE / Hybrid / Graph-augmented 四种检索模式；\n",
        "- Hybrid 相比纯 BM25 / 纯 Dense 在 Hit@3 / Hit@5 上有明显提升；\n",
        "- Graph-augmented 模式在 definition 类问题上命中率更高，证明 law_graph + 语义 rerank 对多跳、交叉引用类问题有效。\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
